[
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "title": "Take-home Exercise 4",
    "section": "",
    "text": "As indicated by the office report and the accompanying infographic:\n\nThe average daily temperatures are expected to rise by 1.4 to 4.6 degrees, and\nThe difference in precipitation between the wet season (November to January) and the dry season (February and June to September) is anticipated to become more distinct.\n\n\n\n\n\nFor this take-home assignment, we are tasked to:\n\nSelect a weather station and retrieve historical daily data on temperature or rainfall from the website of the Meteorological Service Singapore.\nChoose records of daily temperature or rainfall for a month from the years 1983, 1993, 2003, 2013, and 2023, and then craft a data visualisation driven by analytics.\nIncorporate suitable interactive features to improve the experience of users in exploring data and/or in visual storytelling.\n\nFor this take home exercise 3, we have chosen the Changi weather station and decided to focus on the daily temperature data for the month of February across the years 1983, 1993, 2003, 2013, and 2023 to examine the hypothesis suggesting an increase in daily average temperatures between 1.4 to 4.6 degrees Celsius."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#setting-the-scene-for-this-take-home-exercise",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#setting-the-scene-for-this-take-home-exercise",
    "title": "Take-home Exercise 4",
    "section": "",
    "text": "As indicated by the office report and the accompanying infographic:\n\nThe average daily temperatures are expected to rise by 1.4 to 4.6 degrees, and\nThe difference in precipitation between the wet season (November to January) and the dry season (February and June to September) is anticipated to become more distinct."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#the-task",
    "title": "Take-home Exercise 4",
    "section": "",
    "text": "For this take-home assignment, we are tasked to:\n\nSelect a weather station and retrieve historical daily data on temperature or rainfall from the website of the Meteorological Service Singapore.\nChoose records of daily temperature or rainfall for a month from the years 1983, 1993, 2003, 2013, and 2023, and then craft a data visualisation driven by analytics.\nIncorporate suitable interactive features to improve the experience of users in exploring data and/or in visual storytelling.\n\nFor this take home exercise 3, we have chosen the Changi weather station and decided to focus on the daily temperature data for the month of February across the years 1983, 1993, 2003, 2013, and 2023 to examine the hypothesis suggesting an increase in daily average temperatures between 1.4 to 4.6 degrees Celsius."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#loading-necessary-r-packages",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#loading-necessary-r-packages",
    "title": "Take-home Exercise 4",
    "section": "2.1 Loading Necessary R packages",
    "text": "2.1 Loading Necessary R packages\nWe will utilise the following packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\nggthemes is an R package that offers additional themes, geoms, and scales for ‘ggplot2’\n\nThe code which loads the R packages:\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse, dplyr, ggthemes)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#import-dataset",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#import-dataset",
    "title": "Take-home Exercise 4",
    "section": "2.2 Import dataset",
    "text": "2.2 Import dataset\nOf course our next step involves importing the dataset. As mentioned earlier, we will be analysing data from the Changi weather stations for the year 1983, 1993, 2003, 2013 and 2023.\nFirstly, we need to import the 5 csv files using read_csv. We want to read and combine all the files as feb_combined since they all the files have the common column names and same number of columns.\nAlso, we have found out that the 2023 dataset, latin characters are present on some of the columns.\n\nï..Station\n“Mean.Temperature..Â.C.”\n“Maximum.Temperature..Â.C.”\n“Minimum.Temperature..Â.C.”\n\nSince we are only focusing on temperature data, we will discard the columns related to rainfall and windspeed. Also, I will rename these columns below accordingly.\n\nMean Temperature (°C) -&gt; meantemp\nMaximum Temperature (°C) -&gt; maxtemp\nMinimum Temperature (°C) -&gt; mintemp\n\nThen I also will create a new column to find out the difference between the maxtemp and mintemp on a daily basis.\nThe following code snippet will outline the sequential steps we will undertake:\n\nlibrary(dplyr)\n\n# Function to read and preprocess each file\nread_and_preprocess &lt;- function(file_path, encoding = \"latin1\", is_2023 = FALSE) {\n  data &lt;- read.csv(file_path, fileEncoding = encoding)\n  \n  # If the file is for the year 2023, rename columns with encoding issues\n  if(is_2023) {\n    data &lt;- rename(data, \n                   Station = `ï..Station`, \n                   `Mean.Temperature...C.` = `Mean.Temperature..Â.C.`,\n                   `Maximum.Temperature...C.` = `Maximum.Temperature..Â.C.`,\n                   `Minimum.Temperature...C.` = `Minimum.Temperature..Â.C.`)\n  }\n  \n  # Select and rename columns for consistency\n  data %&gt;%\n    select(Station, Year, Month, Day, `Mean.Temperature...C.`, `Maximum.Temperature...C.`, `Minimum.Temperature...C.`) %&gt;%\n    rename(meantemp = `Mean.Temperature...C.`, \n           maxtemp = `Maximum.Temperature...C.`, \n           mintemp = `Minimum.Temperature...C.`) %&gt;%\n    mutate(difftemp = maxtemp - mintemp)\n}\n\n# Read and preprocess each file, with special handling for the 2023 file\nfeb_combined &lt;- bind_rows(\n  read_and_preprocess(\"data/CHANGI_FEB1983.csv\"),\n  read_and_preprocess(\"data/CHANGI_FEB1993.csv\"),\n  read_and_preprocess(\"data/CHANGI_FEB2003.csv\"),\n  read_and_preprocess(\"data/CHANGI_FEB2013.csv\"),\n  read_and_preprocess(\"data/CHANGI_FEB2023.csv\", is_2023 = TRUE)\n)\n\nAfterwards, we want to find out the average temperature across the years. We will name this column yearly_avg_temp.\n\n# Add a new column with the mean temperature for each year\nfeb_combined &lt;- feb_combined %&gt;%\n  group_by(Year) %&gt;%\n  mutate(yearly_avg_temp = mean(meantemp, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nNote\n\n\n\nThe code below is to display the combined file:\n\nDT::datatable(feb_combined, class= \"compact\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#scatterplot",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#scatterplot",
    "title": "Take-home Exercise 4",
    "section": "3.1 Scatterplot",
    "text": "3.1 Scatterplot\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(feb_combined, aes(x = as.Date(paste(Year, Month, Day, sep=\"-\")), y = meantemp)) +\n  geom_point(aes(text = paste(\"Date:\", paste(Year, Month, Day, sep=\"-\"), \"\\nTemp:\", meantemp, \"°C\")), size = 2, color = \"blue\") + # Keep points for daily temperatures\n  geom_line(data = feb_combined, aes(x = as.Date(paste(Year, Month, Day, sep=\"-\")), y = yearly_avg_temp, group = 1), color = \"red\", size = 0.5) + # Keep the red line for yearly average temperatures\n  scale_x_date(breaks = as.Date(c(\"1983-02-01\", \"1993-02-01\", \"2003-02-01\", \"2013-02-01\", \"2023-02-01\")),\n               labels = c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\"),\n               date_labels = \"%Y\") +\n  labs(title = \"Daily and Yearly Mean Temperature Over Years\",\n       x = \"Year\",\n       y = \"Temperature (°C)\") +\n  theme_minimal()\n\n# Convert to interactive plotly plot\ninteractive_p1 &lt;- ggplotly(p1, tooltip = \"text\")\n\n# Display the plot\ninteractive_p1\n\n\n\n\nThis scatter plot visualises two types of temperature data over a span of several years, from before 1983 to 2023:\n\nDaily Mean Temperature (Blue Dots): Each blue dot represents the mean temperature recorded on a specific day. The vertical axis shows the temperature in degrees Celsius (°C), while the horizontal axis represents the years. The exact date and temperature are displayed when you hover over a blue dot, as shown in the tooltip for the date 2003-2-23 with a mean temperature of 27.5 °C.\nAverage Annual Temperature (Red Line): The red line indicates the trend of the average annual temperature over the years. It appears to have a fluctuating pattern, with some years being warmer on average than others.\n\nThe scatter plot also suggests a wide range of daily temperatures within any given year, as seen by the vertical spread of blue dots for each year. The red line helps to identify whether there is an overall trend of increasing or decreasing average temperatures, which could be an indicator of climate patterns or changes. The plot is a useful way to visually compare daily temperatures to the average trend over a long time period.\n\n\n\n\n\n\nWhy is interactivity beneficial here?\n\n\n\n\nDetailed Information on Demand: The ability to hover over individual data points to obtain specific information (such as the exact date and temperature) allows us users to explore the data in depth without overwhelming the visual presentation. In the provided scatter plot above, this means we can see the exact temperature on a given day, which is crucial for detailed analysis or for identifying outliers and anomalies.\nClarity in a Dense Plot: With many data points, a static scatter plot can become cluttered and difficult to read. Interactivity allows us users to focus on individual points of interest without being distracted by the sheer volume of data.\nTrend Identification: By interacting with the data points along the trend line, we can observe how the annual average temperature changes over time, making it easier to spot patterns such as warming or cooling trends."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#lineplot",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#lineplot",
    "title": "Take-home Exercise 4",
    "section": "3.2 Lineplot",
    "text": "3.2 Lineplot\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n# Create the interactive line plot with customised hover text and x-axis ticks\np &lt;- plot_ly(data = feb_combined, x = ~Year, y = ~yearly_avg_temp, type = 'scatter', mode = 'lines+markers',\n             marker = list(size = 10, color = 'red'), line = list(color = 'red'),\n             hovertemplate = paste(\"Year: %{x}&lt;br&gt;Temperature: %{y} °C&lt;extra&gt;&lt;/extra&gt;\")) %&gt;%\n  layout(title = \"Yearly Average Temperatures (1983, 1993, 2003, 2013, 2023)\",\n         xaxis = list(title = \"Year\", \n                      tickvals = c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\"), # Specify which ticks to show\n                      ticktext = c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\")), # Specify labels for the ticks\n         yaxis = list(title = \"Yearly Average Temperature (°C)\"),\n         hovermode = \"closest\")\n\n# Render the plot with specified x-axis ticks\np\n\n\n\n\n\n\n\n\n\n\nKey Findings:\n\n\n\n\nInitial Point (1983): The graph starts at a peak with the average annual temperature recorded at 28.06 °C in 1983. This represents the highest recorded temperature over the 40-year span depicted.\nFirst Decade Drop (1993): There is a sharp decline over the next decade to 26.71 °C in 1993. This decrease of approximately 1.35 °C is quite significant, suggesting a notable cooling period during these ten years.\nRecovery Phase (2003): The year 2003 shows a rebound with the temperature rising to 27.09 °C. Although this is an increase of about 0.38 °C from 1993, it’s still below the starting temperature in 1983 by nearly 1 °C.\nLowest Point (2013): The year 2013 marks the lowest temperature on the plot at 26.53 °C. This further decrease suggests a continuation of the cooling trend, with temperatures dropping by approximately 0.56 °C from 2003 and 1.53 °C from 1983.\nPartial Recovery (2023): By 2023, the temperature rises again to 26.95 °C. This increase of 0.42 °C from 2013 indicates a slight warming trend. However, the temperature in 2023 is still below the initial 1983 temperature by 1.11 °C.\n\n\n\nThe overall trend appears to be a downward trajectory from 1983 to 2013 with a slight increase in 2023. However, the graph does not show a simple linear decrease; rather, it fluctuates, suggesting variability in average temperatures over time. This could be due to a variety of natural climatic cycles or other environmental factors influencing average temperatures."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#heatmap",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#heatmap",
    "title": "Take-home Exercise 4",
    "section": "3.3 Heatmap",
    "text": "3.3 Heatmap\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n# Ensure 'Year' is treated as a factor with only display the 5 years\nfeb_combined$Year &lt;- factor(feb_combined$Year, levels = c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\"))\n\n# Create the heat map with ggplot, specifying y-axis breaks\np &lt;- ggplot(feb_combined, aes(x = Day, y = Year, fill = meantemp)) + \n  geom_tile(color = \"white\", size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + # Using Tufte theme for a clean look\n  scale_fill_gradient(name = \"°C\", low = \"lightyellow\", high = \"red\") + # Adjust colour gradient\n  scale_y_discrete(limits = c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\")) + # Specify y-axis to show only these years\n  labs(x = NULL, \n       y = NULL, \n       title = \"Daily Mean Temperature in Changi for February\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8))\n\n# Convert the ggplot object to an interactive plotly object\ninteractive_p &lt;- ggplotly(p)\n\n# Display the interactive plot\ninteractive_p\n\n\n\n\nThis heatmap visualises the daily mean temperatures for the month of February across five different years: 1983, 1993, 2003, 2013, and 2023.\n\nThe X-axis represents the days of February, ranging from 1 to 28.\nThe Y-axis lists the years in descending order, with 2023 at the top and 1983 at the bottom.\nEach cell in the heatmap corresponds to a specific day in February for a given year.\nThe colour of each cell indicates the mean temperature for that day, according to the colour scale on the right side of the heatmap. The scale ranges from light colours (cooler temperatures) to dark colours (warmer temperatures). Lighter shades of the colour represent cooler temperatures, closer to 25°C, while darker shades signify warmer temperatures, approaching 28°C.\n\nFor instance, if one were to hover over a particular cell:\n\nThe day would be indicated.\nThe year would be shown.\nThe mean temperature for that specific day and year would be displayed.\n\nWith reference to the image below, we can hover over the 27th February 2024 with a mean temperature of 26.7°C.\n\nThe heatmap shows variations in temperature across different days and years at a glance. Warmer days are immediately noticeable with darker colours, while cooler days are indicated by lighter colours. One can observe patterns such as particularly warm or cool periods during February for each year and compare the overall temperature profile across years. It seems there are fluctuations in temperature from year to year, with some years having wider spreads of temperatures throughout the month, while others show more uniformity.\n\n\n\n\n\n\nWhy is interactivity useful here?\n\n\n\nInteractivity functionality in a heatmap, such as the ability to hover over cells to display specific data points, is particularly useful for several reasons:\nPrecision: While the colour gradations indicate temperature differences, precise values cannot be determined solely by sight, especially when dealing with a colour spectrum. Hovering to get exact figures allows for accurate data interpretation.\nDetail: A heatmap can only show so much detail at once. Interactivity allows users to delve into the data, seeing the exact mean temperature for any day of interest without overcrowding the visual with numbers.\nComparison: It enables quick and easy comparisons between different days or years. Users can hover over various parts of the heatmap to compare specific data points without referring to a legend or scale repeatedly.\nUser Engagement: Interactivity increases user engagement. Users who can interact with the data are more likely to spend time understanding the trends and anomalies presented.\nAccessibility: For those with colour vision deficiencies, distinguishing between colours might be challenging. Interactive elements that display numerical data can make the information accessible to a wider audience."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#box-plot-across-5-years",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#box-plot-across-5-years",
    "title": "Take-home Exercise 4",
    "section": "3.4 Box Plot across 5 years",
    "text": "3.4 Box Plot across 5 years\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nfeb_combined$Year &lt;- as.factor(feb_combined$Year)\n\n# Create the Plotly Box Plot\np &lt;- plot_ly(feb_combined, y = ~`meantemp`, x = ~Year, type = 'box',\n             color = ~Year, \n             hoverinfo = 'y+x') %&gt;%\n  layout(title = \"Box Plot of Daily Mean Temperatures for February Over Decades\",\n         xaxis = list(title = \"Year\"),\n         yaxis = list(title = \"Mean Temperature (°C)\"))\n\n# Display the plot\np\n\n\n\n\nThe box plot illustrates the distribution of daily mean temperatures for the month of February over five distinct years: 1983, 1993, 2003, 2013, and 2023. For each year, the data is summarised as follows:\n\n\n\n\n\n\nKey Findings\n\n\n\n1983:\n\nThe maximum daily mean temperature reached 28.8°C.\nThe upper quartile (Q3) temperature was 28.55°C, indicating that 75% of the days had a mean temperature of 28.55°C or lower.\nThe median temperature was 28.1°C, which is the midpoint of the data.\nThe lower quartile (Q1) temperature was 27.75°C, suggesting that 25% of the days had a mean temperature below this value.\nThe minimum temperature recorded was 26.8°C.\n\n1993:\n\nThe temperatures peaked at 27.5°C.\nThe third quartile was observed at 27°C.\nThe median temperature for this year was slightly lower at 26.75°C.\nThe first quartile was marked at 26.45°C.\nThere was a notable outlier at 25.5°C, which was significantly lower than the expected range.\n\n2003:\n\nThe highest daily mean temperature noted was 28.2°C.\nThe temperature at the third quartile was 27.77°C.\nThe median temperature was 27.35°C.\nThe first quartile temperature came in at 26.45°C.\nThe lowest temperature recorded for the month was 25.3°C.\n\n2013:\n\nThe maximum temperature reached a similar level as in 2003, at 28.3°C.\nThe upper quartile temperature decreased to 27.2°C.\nThe median temperature was 26.64°C, indicating a slight decrease from 2003.\nThe lower quartile was at 26°C. - The minimum temperature dropped to 24.6°C, showing a significant decrease from previous years.\n\n2023:\n\nThe highest temperature observed was 28°C.\nThe third quartile temperature was at 27.5°C.\nThe median temperature was 27.05°C, suggesting a slight uptick from 2013. - The first quartile was at 26.7°C.\nThe minimum temperature saw a slight increase from the previous decade at 24.9°C, with a noticeable outlier just below the lower fence of 25.6°C.\n\n\n\nFrom 1983 to 2023, there’s a noticeable fluctuation in temperatures with both the median and the interquartile range varying from year to year. The median temperature appears to show slight variations, without a clear upward or downward trend. However, there is evidence of increasing variability in temperatures, as seen in the wider interquartile ranges in the later years, particularly in 2023."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html",
    "title": "In-class Exercise 01: Now You See It!",
    "section": "",
    "text": "In this hands-on exercise, two R packages will be used. They are:\n\ntidyverse, and\n[haven] (https://www.tidyverse.org/)\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html#loading-r-packages",
    "title": "In-class Exercise 01: Now You See It!",
    "section": "",
    "text": "In this hands-on exercise, two R packages will be used. They are:\n\ntidyverse, and\n[haven] (https://www.tidyverse.org/)\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html#importing-pisa-data",
    "href": "In-class_Ex/In-class_Ex01/In-Class_Ex01.html#importing-pisa-data",
    "title": "In-class Exercise 01: Now You See It!",
    "section": "Importing PISA data",
    "text": "Importing PISA data\nThe code chunk below uses read_sas() of haven to import PISA data into R environment.\n\nstu_qqq &lt;- read_sas(\"data/cy08msp_stu_qqq.sas7bdat\")\n\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\n\nwrite_rds(stu_qqq_SG,\n          \"data/stu_qqq_SG.rds\")\n\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "The objective of this exercise is to analyse and enhance the charts generated by a peer using R packages in Take-home Exercise 1. The evaluation will focus on aspects of clarity and aesthetics. Subsequently, the original design will be reconstructed by applying data visualiation design principles and best practices, utilising ggplot2, its extensions, and tidyverse packages learnt in lesson 1 and 2.\nThe data that we will be using would be the 2022 Programme for International Student Assessment (PISA), which evaluates education systems globally by testing 15-year-old students in mathematics, reading and science. The Student Questionnaire can be downloaded here."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#setting-the-scene-for-this-exercise",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#setting-the-scene-for-this-exercise",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "The objective of this exercise is to analyse and enhance the charts generated by a peer using R packages in Take-home Exercise 1. The evaluation will focus on aspects of clarity and aesthetics. Subsequently, the original design will be reconstructed by applying data visualiation design principles and best practices, utilising ggplot2, its extensions, and tidyverse packages learnt in lesson 1 and 2.\nThe data that we will be using would be the 2022 Programme for International Student Assessment (PISA), which evaluates education systems globally by testing 15-year-old students in mathematics, reading and science. The Student Questionnaire can be downloaded here."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-necessary-r-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-necessary-r-packages",
    "title": "Take-home Exercise 2",
    "section": "2.1 Loading Necessary R packages",
    "text": "2.1 Loading Necessary R packages\nWe will utilise the following packages:\n\nhaven: Facilitates the import and export of ‘SPSS,’ ‘Stata,’ and ‘SAS’ files.\ntidyverse: A collection of packages for data manipulation and visualisation, including dplyr, ggplot2 and others.\nggrepel: An R package used with ggplot2 to enhance the positioning of text labels in plots, ensuring they avoid overlapping with data points, for a more readable visualisation.\nPatchwork: An R package designed for creating composite figures using ggplot2.\nggthemes: An R package that offers additional themes, geoms and scales for ggplot2.\nhrbrthemes: An R package that provides themes and theme components for ggplot2 visualisations, mainly focusing on typography-centric design.\n\nThe code which loads the R packages:\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, haven)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-dataset",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-dataset",
    "title": "Take-home Exercise 2",
    "section": "2.2 Import dataset",
    "text": "2.2 Import dataset\nOf course our next step involves importing the dataset. The following code snippet will outline the sequential steps we will undertake.\n\nstu_qqq &lt;- read_sas('data/cy08msp_stu_qqq.sas7bdat')\n\nSince we are focusing only in Singapore context, we will filter to only include Singapore.\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\nSave the filtered dataset as an RDS file to simplify subsequent data imports.\n\nwrite_rds(stu_qqq_SG, 'data/stu_qqq_SG.rds')\n\nRead the RDS file that has been exported.\n\nstu_qqq_SG &lt;- read_rds('data/stu_qqq_SG.rds')\n\nThis code will undergo pre-processing to select all the required variables in which we need to do further analysis on. A cleaner code have been compiled below.\n\n\n\n\n\n\nCode Explanation\n\n\n\nIn the R code below, we begin by selecting specific columns of interest from the dataset stu_qqq_SG. Following this, we will calculate the row means for math, science and reading scores, providing a more comprehensive measure of individual performance. The column names are then renamed to enhance clarity. Afterwards, a subset of columns is selected for focused analysis, which includes gender, socioeconomic status (escs), and educational level (school). Gender and school variables are recoded to more interpretable factors, replacing numeric codes with meaningful and easier to understand labels. The cleaned dataset, named stu_qqq_SG_2, is saved in an RDS file for future use. The RDS file is subsequently read back into the script.\n\n\n\n# Step 1: Select relevant columns\nstu_qqq_SG_1 &lt;- stu_qqq_SG %&gt;%\n  select(ST004D01T, EXPECEDU, PV1MATH, PV2MATH, PV3MATH, PV4MATH, PV5MATH, PV6MATH, PV7MATH, PV8MATH, PV9MATH, PV10MATH, PV1SCIE, PV2SCIE, PV3SCIE, PV4SCIE, PV5SCIE, PV6SCIE, PV7SCIE, PV8SCIE, PV9SCIE, PV10SCIE, PV1READ, PV2READ, PV3READ, PV4READ, PV5READ, PV6READ, PV7READ, PV8READ, PV9READ, PV10READ, ESCS)\n\n# Step 2: Calculate row means for math, science, and reading\nstu_qqq_SG_1 &lt;- stu_qqq_SG_1 %&gt;%\n  mutate(maths = rowMeans(across(c(PV1MATH, PV2MATH, PV3MATH, PV4MATH, PV5MATH, PV6MATH, PV7MATH, PV8MATH, PV9MATH, PV10MATH))),\n         science = rowMeans(across(c(PV1SCIE, PV2SCIE, PV3SCIE, PV4SCIE, PV5SCIE, PV6SCIE, PV7SCIE, PV8SCIE, PV9SCIE, PV10SCIE))),\n         reading = rowMeans(across(c(PV1READ, PV2READ, PV3READ, PV4READ, PV5READ, PV6READ, PV7READ, PV8READ, PV9READ, PV10READ))))\n\n# Step 3: Rename columns for clarity\nstu_qqq_SG_1 &lt;- stu_qqq_SG_1 %&gt;%\n  rename(gender = ST004D01T, escs = ESCS, school = EXPECEDU)\n\n# Step 4: Select specific columns for further analysis\nstu_qqq_SG_2 &lt;- stu_qqq_SG_1 %&gt;%\n  select(gender, escs, school, maths, science, reading)\n\n# Step 5: Recode gender and school columns\nstu_qqq_SG_2 &lt;- stu_qqq_SG_2 %&gt;%\n  mutate(gender = ifelse(gender == \"1\", \"Female\", \"Male\"),\n         school = case_when(\n           school == \"2\" ~ \"Lower Sec\",\n           school == \"3\" ~ \"Upper Sec\",\n           school == \"5\" ~ \"Post Sec\",\n           school == \"6\" ~ \"Diploma\",\n           school == \"7\" ~ \"Degree\",\n           school == \"8\" ~ \"Masters\",\n           school == \"9\" ~ \"PhD\"\n         ))\n\n# Step 6: Write the cleaned data to an RDS file\nwrite_rds(stu_qqq_SG_2, \"data/stu_qqq_SG_2.rds\")\n\n# Step 7: Read the cleaned data from the RDS file\nstu_qqq_SG_2 &lt;- read_rds(\"data/stu_qqq_SG_2.rds\")\n\n\n\n\n\n\n\nCode Explanation - as.factor() function\n\n\n\nMoving on, the provided code transforms the ‘gender’ and ‘school’ columns in the R data frame stu_qqq_SG_2 into factors using the as.factor() function. This conversion is beneficial when dealing with categorical variables, as factors in R provide a structured representation of such data. The gender factor represents two categories, “Male” and “Female,” while the school factor likely denotes different levels of education, such as “Lower Sec,” “Upper Sec,” and others. Converting these columns to factors ensures that R recognises and treats them appropriately as categorical variables during statistical analysis, allowing for better representation and interpretation of the data. Subsequently, a summary statistics report is generated, offering a quick overview of the of the cleaned dataset.\n\n\n\n# Step 1: Converting gender and school into factors (categorical variables)\nstu_qqq_SG_2$gender &lt;- as.factor(stu_qqq_SG_2$gender)\n\nstu_qqq_SG_2$school &lt;- as.factor(stu_qqq_SG_2$school)\n\n# Step 2: Display summary statistics\nsummary(stu_qqq_SG_2)\n\n    gender          escs              school         maths      \n Female:3248   Min.   :-3.5488   Degree  :2062   Min.   :262.6  \n Male  :3358   1st Qu.:-0.2327   Diploma :1299   1st Qu.:506.2  \n               Median : 0.4817   Masters :1289   Median :582.4  \n               Mean   : 0.2904   PhD     :1045   Mean   :574.0  \n               3rd Qu.: 0.9036   Post Sec: 406   3rd Qu.:648.4  \n               Max.   : 3.2780   (Other) : 296   Max.   :842.7  \n               NA's   :47        NA's    : 209                  \n    science         reading     \n Min.   :242.0   Min.   :158.6  \n 1st Qu.:498.9   1st Qu.:477.4  \n Median :571.2   Median :553.6  \n Mean   :561.0   Mean   :542.5  \n 3rd Qu.:629.3   3rd Qu.:616.1  \n Max.   :801.9   Max.   :797.6"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#distribution-of-subjects-scores",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#distribution-of-subjects-scores",
    "title": "Take-home Exercise 2",
    "section": "3.1 Distribution of Subjects’ Scores",
    "text": "3.1 Distribution of Subjects’ Scores\n\n3.1.1 Original Design\nA histogram below is used to reveal the distribution of scores for each respective subject, in this particular case, the Maths scores.\n\n\n\n\n\n\n\n\n\n\n\n3.1.2 Critique\n\n\nCritique - Clarity\n\nThe title of the graph, “Histogram of Maths scores”, clearly states what the data represents, which is good for immediate understanding.\nThe data presented appears to be continuous, and the histogram effectively shows the distribution of the math scores. However, there are no markers for the mean or median score, which could provide additional useful information about the dataset.\n\n\n\nCritique - Aesthetics\n\nThe colour scheme is simple and the bars are easily distinguishable, which makes the graph aesthetically pleasing and clear to read.\nThe grey background is neutral and does not distract from the data, but a white background could be considered for a cleaner look.\nThe text is not capitalised, which is fine for informality but could be capitalised for a more formal and professional appearance.\nThere is a consistent use of colour and no extraneous graphical elements, which is good. However, the graph could benefit from a cleaner font and perhaps a grid for easier reading of values.\n\n\n\n3.1.3 Remake\nTo improve the histogram in terms of clarity and aesthetics,\n\n\nRemake - Clarity:\n\nInclude annotations for key statistics such as the mean or median to give viewers a better understanding of the central tendency of the data.\n\n\n\nRemake - Aesthetics:\n\nChange the background to white for a more professional look.\nCapitalise the first letter of each label for a more formal presentation.\nAdd a light grid to make it easier to read values from the graph.\nChoose a cleaner, more professional font for all text elements.\n\n\n# Calculate the mean math score for annotation\nmean_score &lt;- mean(stu_qqq_SG_2$maths)\n\nggplot(data = stu_qqq_SG_2, aes(x = maths)) +\n  geom_histogram(bins = 20, \n                 boundary = 100,\n                 color = \"black\",      \n                 fill = \"light blue\") + \n  geom_vline(aes(xintercept = mean_score), \n             color = \"red\", linetype = \"dashed\", size = 1) +\n  annotate(\"text\", x = mean_score, y = Inf, label = paste(\"Mean:\", round(mean_score, 2)), \n           vjust = 0.95, color = \"red\") +\n  labs(title = \"Histogram of Maths Scores\",\n       x = \"Math Score\",\n       y = \"Number of Students\") +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    axis.title = element_text(face = \"bold\"),\n    panel.grid.major = element_line(color = \"grey80\", size = 0.5),\n    panel.background = element_rect(fill = \"white\"),\n    axis.text = element_text(color = \"black\")\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#scatterplot-of-socioeconomic-status-vs-maths-score",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#scatterplot-of-socioeconomic-status-vs-maths-score",
    "title": "Take-home Exercise 2",
    "section": "3.2 Scatterplot of Socioeconomic Status vs Maths Score",
    "text": "3.2 Scatterplot of Socioeconomic Status vs Maths Score\n\n3.2.1 Original Design\nA scatterplot below is used to reveal the relationship between the Socioeconmic status against the scores for each respective subject, in this particular case, the Maths scores.\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Critique\n\n\nCritique - Clarity\n\nThe title is descriptive, but it could be improved to concisely convey the key focus of the analysis, which is the relationship between socioeconomic status and math scores.\nWithout a regression line, it is difficult for the viewer to immediately grasp the nature of the relationship between the two variables.\nThe scatterplot does not indicate the correlation coefficient, which quantitatively summarises the strength and direction of the linear relationship.\nOverplotting may be obscuring the density of points in certain areas, making it difficult to assess the distribution of data accurately.\n\n\n\nCritique - Aesthetics\n\nThe plot uses a basic colour scheme, which is clear but does not make use of colour to convey additional information or to improve visual appeal.\nAll points are of the same size and colour, which could be varied to show density.\nThe grey background is neutral but does nott enhance the data visualisation; a lighter background with subtle gridlines could improve readability.\n\n\n\n3.2.3 Remake\nTo improve the scatterplot in terms of clarity and aesthetics,\n\n\nRemake - Clarity\n\nAdd a regression line to visually represent the relationship between math scores and socioeconomic status. This would not only clarify the direction and steepness of the relationship but also help in identifying patterns or deviations.\nCalculate and display the correlation coefficient on the plot to provide a clear, numerical summary of the relationship’s strength.\nImplement techniques to mitigate overplotting, such as adjusting the alpha transparency of points.\n\n\n\nRemake - Aesthetics\n\nIntroduce a colour gradient to reflect the density of overlapping points, which could enhance visual appeal and clarity.\nApply a more sophisticated theme, like theme_bw(), which provides a clean and professional look with white background and gridlines.\nIncrease the size and change the colour of the regression line, in this case brigh red, to make it stand out against the points.\n\n\n# Calculate the Pearson correlation coefficient, handling NA values appropriately\ncorrelation &lt;- cor(stu_qqq_SG_2$maths, stu_qqq_SG_2$escs, use = \"complete.obs\")\n\n# Create the scatterplot with improvements mentioned above\np &lt;- ggplot(data = stu_qqq_SG_2, aes(x = maths, y = escs)) +\n  geom_point(alpha = 0.4) +  # Adjust alpha for overplotting\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +  # Add regression line\n  ggtitle(\"Relationship Between Socioeconomic Status and Math Scores\") +\n  labs(x = \"Math Score\", y = \"Socioeconomic Status (PISA Index)\") +\n  theme_bw(base_size = 14) +  # Use a theme with white background\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),\n    axis.title = element_text(size = 14, face = \"bold\")\n  )\n\n# If correlation is not NA, add it to the plot\nif (!is.na(correlation)) {\n  p &lt;- p + annotate(\"text\", x = Inf, y = Inf, label = sprintf(\"r = %.2f\", correlation),\n                    hjust = 1.1, vjust = 1.1, color = \"red\", size = 5)\n}\n\n# Print the plot\nprint(p)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn this code, geom_point() is used with an alpha value to handle overplotting, geom_smooth() adds the regression line, and annotate() adds the correlation coefficient."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#distribution-of-socioeconomic-status-by-gender",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#distribution-of-socioeconomic-status-by-gender",
    "title": "Take-home Exercise 2",
    "section": "3.3 Distribution of Socioeconomic Status (by Gender)",
    "text": "3.3 Distribution of Socioeconomic Status (by Gender)\n\n3.3.1 Original Design\nA geom_density plot below is used to reveal the distribution between the Socioeconmic status by Gender.\n\nggplot(data=stu_qqq_SG_2, \n       aes(x = escs, \n           colour = gender)) +\n  geom_density()+\n  ggtitle(\"Distribution of Socioeconomic Status (by Gender)\")+\n  labs(x = \"Socioeconomic Status - PISA Index\")\n\n\n\n\n\n\n\n\n\n\n3.3.2 Critique\n\n\nCritique - Clarity\n\nRhe legend is clear and distinguishes between genders, which is good. However, more neutral colours could be used.\nThe plot indicates skewness, but without the actual data points or additional statistical annotations, it is difficult to validate the findings stated about the skewness or the comparative peaks of the distribution.\nThe x-axis is well labeled, but the y-axis is not labeled at all, which could lead to confusion about what the density values represent.\n\n\n\nCritique - Aesthetics\n\nThe colours are easily distinguishable but as mentioned earlier, may not be the best choice due to potential gender stereotyping.\nThe default grey background and grid might not be the most aesthetically pleasing. A cleaner look might be achieved with a white background and less prominent grid lines.\nThe density lines are quite thin. Increasing their thickness could make them stand out more clearly against the background.\n\n\n\n3.3.3 Remake\nTo improve the density plot in terms of clarity and aesthetics,\n\n\nRemake - Clarity\n\nAdding annotations for mean, median or mode for each gender could provide more context.\nIf the lines are overlapping significantly, consider using fill with alpha to differentiate the distributions while showing overlap.\n\n\n\nRemake - Aesthetics\n\nIn terms ot theme, we are using theme_minimal() for a more modern, clean aesthetic.\nFor colour palette, we will opt for a colourblind-friendly palette or more neutral tones.\nWe will also increase the line thickness for better visibility.\n\n\n# Calculate mean for each gender\nstats &lt;- stu_qqq_SG_2 %&gt;%\n  group_by(gender) %&gt;%\n  summarise(mean = mean(escs, na.rm = TRUE))\n\n# Create the density plot with annotations for mean \nggplot(data = stu_qqq_SG_2, aes(x = escs, fill = gender)) +\n  geom_density(alpha = 0.6) + # Use fill with transparency instead of color for lines\n  scale_fill_manual(values = c(\"#1f77b4\", \"#ff7f0e\")) + # Example of a colourblind-friendly palette\n  geom_vline(data = stats, aes(xintercept = mean, color = gender), linetype = \"dashed\") +\n  ggtitle(\"Distribution of Socioeconomic Status by Gender\") +\n  labs(x = \"Socioeconomic Status - PISA Index\", y = \"Density\") +\n  theme_minimal(base_size = 14) + # A cleaner theme\n  theme(legend.position = \"top\", # Position the legend on top\n        plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),\n        axis.title = element_text(size = 14, face = \"bold\"),\n        axis.text = element_text(color = \"black\"),\n        legend.title = element_blank()) + # Remove the legend title\n  scale_color_manual(values = c(\"#1f77b4\", \"#ff7f0e\"))  # Match line colours to the fill colours\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn density plots, the y-axis represents the density of the data, which is a function of the number of observations and the bin width used in the kernel density estimation. Therefore, it may not always start at 0, especially if there are no values in the data near 0.\nFor the x-axis, which represents the actual data points, it is often a good practice to start at 0 if it makes sense for the data. However, in our case, for socioeconomic status or indices like PISA, which can have negative values and often do not start at 0, it may be more appropriate to start at the minimum value of the data or a meaningful reference point that provides context."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#distribution-of-maths-scores-by-expected-school",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#distribution-of-maths-scores-by-expected-school",
    "title": "Take-home Exercise 2",
    "section": "3.4 Distribution of Maths Scores by Expected School",
    "text": "3.4 Distribution of Maths Scores by Expected School\n\n3.4.1 Original Design\nA histogram below is used to reveal the distribution between the expected school against the scores for each respective subject, in this particular case, the Maths scores.\n\nggplot(data=stu_qqq_SG_2, \n       aes(x= maths, \n           fill = school)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")+\n  ggtitle(\"Distribution of Maths scores (by Expected School)\")+\n  labs(x = \"Math Score\")+\n  labs(y= \"Number of students\")\n\n\n\n\n\n\n\n\n\n\n3.4.2 Critique\n\n\nCritique - Clarity\n\nOverlapping Bars: The histogram uses stacked bars to represent different schools, which makes it difficult to compare the distributions of math scores between schools, especially for those not at the bottom of the stack.\nColour Choice: The colours are distinct, but there are so many that it becomes hard to differentiate and track across the histogram. This is particularly challenging for individuals with colour vision deficiencies.\nLegend Positioning: The legend is positioned inside the plot area, which can potentially cover some of the data and reduce readability.\nBins: With a bin width set to produce 20 bins, some detail in the distribution may be lost, especially if the range of math scores is broad.\n\n\n\nCritique - Aesthetics\n\nColour Saturation: The colours are very saturated, which can be visually overwhelming and make it harder to focus on the data.\nGridlines: The absence of horizontal gridlines can make it hard to estimate the number of students for a given bin.\nBar Borders: The grey borders on the bars add visual clutter, especially where colours are similar.\n\n\n\n3.4.3 Remake\nTo improve the histogram in terms of clarity and aesthetics,\n\n\nRemake - Clarity\n\nSwitch to Faceted Plot: Instead of stacking, use faceted histograms or side-by-side histograms to compare distributions between schools without overlap.\nSimplify Colour Palette: Use a simpler colour palette with fewer colours or shades to help distinguish between schools, or use patterns instead of colours for differentiation.\nReposition Legend: Move the legend outside the plot area, such as to the bottom or side, to avoid obscuring the data.\n\n\n\nRemake - Aesthetics\n\nWe use a theme with a cleaner aesthetic, such as theme_minimal(), which provides a white background and less intrusive gridlines.\nRemove Bar Borders: We need to eliminate the borders or use a softer colour that does not compete with the fill colour.\nAdd Horizontal Gridlines: We need to include soft horizontal gridlines for easier comparison of heights across the histogram.\n\n\n# Create the histogram with improvements mentioned above\nggplot(data = stu_qqq_SG_2, aes(x = maths, fill = school)) +\n  geom_histogram(position = \"dodge\", bins = 20, color = NA) +  # Use 'position = dodge' to place bars side by side\n  scale_fill_brewer(palette = \"Pastel1\") +  # Use a pastel colour palette for better distinction\n  ggtitle(\"Distribution of Maths Scores by Expected School\") +\n  labs(x = \"Math Score\", y = \"Number of Students\") +\n  theme_minimal(base_size = 14) +  # Cleaner theme\n  theme(legend.position = \"bottom\",  # Move legend to the bottom\n        plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),\n        axis.title = element_text(size = 14, face = \"bold\"),\n        axis.text = element_text(color = \"black\"),\n        panel.grid.major = element_line(color = \"grey80\", size = 0.5),\n        panel.grid.minor = element_blank(),\n        legend.box.background = element_rect(color = \"white\"))  # Add a background to the legend box\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn this code, position = \"dodge\" is used to place the bars side by side instead of stacking them, which greatly improves clarity when comparing between schools. A pastel colour palette from scale_fill_brewer() is used to distinguish the schools while being less visually overwhelming. The legend is moved to the bottom of the plot to avoid obscuring any data."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#boxplot-between-gender-and-maths-scores",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#boxplot-between-gender-and-maths-scores",
    "title": "Take-home Exercise 2",
    "section": "3.5 Boxplot between Gender and Maths Scores",
    "text": "3.5 Boxplot between Gender and Maths Scores\n\n3.5.1 Original Design\nA boxplot below is used to reveal the distribution between maths score and Gender.\n\n\n3.5.2 Critique\n\n\nCritique - Clarity\n\nMean Indication: The red dot indicating the mean is a good addition for showing central tendency, but there is no legend explaining what the red dot signifies. Viewers might not realise it represents the mean math score.\nAxis Labels: While the y-axis is labeled, it could be more descriptive. Instead of “Maths Score,” a label like “Math Score Distribution” might provide more context.\nGender Labeling: The x-axis labels “Female” and “Male” could be more inclusive. The plot does not account for non-binary or other gender identities, which might be relevant depending on the context of the data.\n\n\n\nCritique - Aesthetics\n\nColour Scheme: The use of red for the mean is visually effective, but the rest of the plot is quite monochrome. Utilising a subtle colour for the boxes could improve visual appeal.\nPlot Spacing: The spacing between the two boxplots is quite large, which may not be an efficient use of space.\nGridlines: There are no horizontal gridlines, which can help viewers better estimate the values of the quartiles and the mean.\n\n\n\n3.5.3 Remake\nTo improve the boxplot in terms of clarity and aesthetics,\n\n\nRemake - Clarity\n\nLegend for Mean: Add a legend or annotation to explain the red dot represents the mean.\nAdditional Statistics: Add more summary statistics, such as the median (which the boxplot inherently shows), using different point shapes or colours to provide a fuller picture of the distribution.\n\n\n\nRemake - Aesthetics\n\nColour for Boxes: Introduce a light colour fill within the boxes to enhance visual differentiation between the quartiles and the overall distribution.\nReduce Width: Decrease the width of the individual boxplots to bring them closer together and use space more efficiently.\nGridlines: Add horizontal gridlines for better readability of values.\n\n\n# Enhanced boxplot with additional statistics and legends\nggplot(data = stu_qqq_SG_2, aes(x = gender, y = maths)) +    \n  geom_boxplot(aes(fill = gender)) +\n  scale_fill_manual(values = c(\"#EBF5FB\", \"#FEF9E7\")) + # Subtle colours for the boxes\n  geom_point(stat = \"summary\", aes(color = \"Mean\"), fun.y = \"mean\", size = 4) +\n  geom_point(stat = \"summary\", aes(color = \"Median\"), fun.y = \"median\", size = 4, shape = 18) +\n  ggtitle(\"Boxplot of Math Score by Gender\") +\n  labs(y = \"Math Score Distribution\", x = \"\", color = \"Summary Statistics\") + # More descriptive y-axis label, remove x-axis label\n  scale_color_manual(values = c(\"Mean\" = \"red\", \"Median\" = \"blue\")) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),\n    axis.title = element_text(size = 14, face = \"bold\"),\n    legend.position = \"right\",\n    legend.title.align = 0.5,\n    panel.grid.major.y = element_line(color = \"grey80\", size = 0.5), # Add y gridlines\n    panel.grid.minor = element_blank()\n  ) +\n  coord_flip() # Flip the coordinates into horizontal position\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis code adds subtle colours to the boxplot fills, differentiates between the mean and median with different colours and shapes, and adds y-axis gridlines for better readability. The coord_flip() is included as to flip the boxplots to a horizontal orientation, which is sometimes preferred for readability."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Andreas Schleicher, the education director of OECD, conveyed in a BBC article that Singapore has achieved excellence without significant disparities between children from affluent and underprivileged families (2016). Additionally, several Ministers for Education in Singapore have adopted the slogan “every school a good school.” Despite these efforts, the prevailing public opinion strongly suggests the presence of disparities, particularly between elite and neighbourhood schools, among students from families with varying socioeconomic statuses, and between immigration and non-immigration families.\n\n\n\nThe data that we will be using would be the 2022 Programme for International Student Assessment (PISA), which evaluates education systems globally by testing 15-year-old students in mathematics, reading, and science.\nBy employing some EDA, we would want to find out:\n\nThe distribution of Singaporean students’ proficiency in mathematics, reading and science\nThe correlation between these performance levels and factors such as schools, gender and the socioeconomic status of the students"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Andreas Schleicher, the education director of OECD, conveyed in a BBC article that Singapore has achieved excellence without significant disparities between children from affluent and underprivileged families (2016). Additionally, several Ministers for Education in Singapore have adopted the slogan “every school a good school.” Despite these efforts, the prevailing public opinion strongly suggests the presence of disparities, particularly between elite and neighbourhood schools, among students from families with varying socioeconomic statuses, and between immigration and non-immigration families."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#our-task",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#our-task",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "The data that we will be using would be the 2022 Programme for International Student Assessment (PISA), which evaluates education systems globally by testing 15-year-old students in mathematics, reading, and science.\nBy employing some EDA, we would want to find out:\n\nThe distribution of Singaporean students’ proficiency in mathematics, reading and science\nThe correlation between these performance levels and factors such as schools, gender and the socioeconomic status of the students"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-r-packages",
    "title": "Take-home Exercise 1",
    "section": "2.1 Loading R packages",
    "text": "2.1 Loading R packages\nIn this take-home exercise, tidyverse and haven packages will be used.\nAlso, we will be using these packages listed below:\n\nggrepel is an R package that offers geoms for ggplot2, enabling the repulsion of overlapping text labels\nggthemes is an R package that offers additional themes, geoms, and scales for ‘ggplot2’\nhrbrthemes is an R package that offers typography-centric themes and theme components for ggplot2\npatchwork is an R package designed for creating composite figures using ggplot2\ndplyr is a data manipulation package in R that offers a consistent set of functions, or verbs, to address common data manipulation tasks. It includes functions such as ‘mutate()’ for creating new variables, ‘select()’ for choosing variables by name, ‘filter()’ for selecting cases based on values, ‘summarise()’ for reducing multiple values to a single summary, and ‘arrange()’ for changing the row ordering in a dataset.\n\nnote: The tidyverse package is an “umbrella-package” that installs tidyr, dplyr and several other useful packages for data analysis, such as ggplot2, tibble, etc.\nThe code chunk used is as follows:\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes, dplyr, ggdist, ggridges,\n               tidyverse, haven)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-dataset",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-dataset",
    "title": "Take-home Exercise 1",
    "section": "2.2 Importing the dataset",
    "text": "2.2 Importing the dataset\nOne dataset from PISA is provided for this task, specifically the Student questionnaire data file: cy08msp_stu_qqq.sas7bdat\nThe code chunk below uses read_sas() of haven to import PISA data into R environment.\n\nstu_qqq &lt;- read_sas(\"data/cy08msp_stu_qqq.sas7bdat\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#filtering-data-from-singapore-only",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#filtering-data-from-singapore-only",
    "title": "Take-home Exercise 1",
    "section": "2.3 Filtering data from Singapore only",
    "text": "2.3 Filtering data from Singapore only\nSince our task is to find out students’ performance in various subjects and relationship of performances with regards to other variables in Singapore, we would need to filter data to only include Singapore. Since there is a CNT column, which is a Country column, we will filter it to only include SGP (Singapore).\nThe code chunk to filter SGP only:\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\nSince the original data is huge in file size, we will save the Singapore filtered data as stu_qqq_SG in the data folder.\nThe code chunk to save filtered data as stu_qqq_SG:\n\nwrite_rds(stu_qqq_SG,\n          \"data/stu_qqq_SG.rds\")\n\nTherefore, we will only read the stu_qqq_SG.rds file from now onwards.\nThe code chunk to read stu_qqq_SG.rds file:\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary-statistics-of-stu_qqq_sg-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary-statistics-of-stu_qqq_sg-data",
    "title": "Take-home Exercise 1",
    "section": "2.4 Summary Statistics of stu_qqq_SG data",
    "text": "2.4 Summary Statistics of stu_qqq_SG data\nTo check if we have filtered the correct data to include SG only, we will be displaying first 10 rows using head():\n\nThe outputThe code\n\n\n\n\n# A tibble: 10 × 1,279\n   CNT   CNTRYID CNTSCHID CNTSTUID CYC   NatCen STRATUM SUBNATIO REGION  OECD\n   &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 SGP       702 70200052 70200001 08MS  070200 SGP01   7020000   70200     0\n 2 SGP       702 70200134 70200002 08MS  070200 SGP01   7020000   70200     0\n 3 SGP       702 70200112 70200003 08MS  070200 SGP01   7020000   70200     0\n 4 SGP       702 70200004 70200004 08MS  070200 SGP01   7020000   70200     0\n 5 SGP       702 70200152 70200005 08MS  070200 SGP01   7020000   70200     0\n 6 SGP       702 70200043 70200006 08MS  070200 SGP01   7020000   70200     0\n 7 SGP       702 70200049 70200007 08MS  070200 SGP01   7020000   70200     0\n 8 SGP       702 70200107 70200008 08MS  070200 SGP01   7020000   70200     0\n 9 SGP       702 70200012 70200009 08MS  070200 SGP01   7020000   70200     0\n10 SGP       702 70200061 70200010 08MS  070200 SGP01   7020000   70200     0\n# ℹ 1,269 more variables: ADMINMODE &lt;dbl&gt;, LANGTEST_QQQ &lt;dbl&gt;,\n#   LANGTEST_COG &lt;dbl&gt;, LANGTEST_PAQ &lt;dbl&gt;, Option_CT &lt;dbl&gt;, Option_FL &lt;dbl&gt;,\n#   Option_ICTQ &lt;dbl&gt;, Option_WBQ &lt;dbl&gt;, Option_PQ &lt;dbl&gt;, Option_TQ &lt;dbl&gt;,\n#   Option_UH &lt;dbl&gt;, BOOKID &lt;dbl&gt;, ST001D01T &lt;dbl&gt;, ST003D02T &lt;dbl&gt;,\n#   ST003D03T &lt;dbl&gt;, ST004D01T &lt;dbl&gt;, ST250Q01JA &lt;dbl&gt;, ST250Q02JA &lt;dbl&gt;,\n#   ST250Q03JA &lt;dbl&gt;, ST250Q04JA &lt;dbl&gt;, ST250Q05JA &lt;dbl&gt;, ST250D06JA &lt;chr&gt;,\n#   ST250D07JA &lt;chr&gt;, ST251Q01JA &lt;dbl&gt;, ST251Q02JA &lt;dbl&gt;, ST251Q03JA &lt;dbl&gt;, …\n\n\n\n\n\nhead(stu_qqq_SG,10)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-subjects-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-subjects-data",
    "title": "Take-home Exercise 1",
    "section": "2.5 Preparing Subjects Data",
    "text": "2.5 Preparing Subjects Data\nIn order to assess students’ performance in various subjects, including Mathematics, Reading and Science, we must identify the columns that correspond to these specific subjects.\nWith reference to PISA website, we can utilise plausible estimates for assessing student proficiency. PISA evaluates student achievement using plausible values (PVs), derived from Item Response Theory models (refer to Chapter 5 of the PISA Data Analysis Manual: SAS or SPSS, Second Edition, or the accompanying guide “Scaling of Cognitive Data and Use of Students Performance Estimates” for detailed information). These models fundamentally deduce a student’s ability from their test performance. In application, plausible values are produced through multiple imputations, considering pupils’ responses to the randomly assigned subset of test questions and their input in background questionnaires.\n\n2.5.1 Preparing Maths Data\nAfter looking through the dataset, we have determined that the columns denoting Mathematics performance are PV1MATH to PV10MATH.\nConsequently, we will compute the average of these plausible values using the rowMeans() function. A new column, called MATHEMATICS, will be generated to store the calculated average plausible values for the Mathematics subject.\nThe corresponding code snippet is as follows:\n\n# Select the columns containing math plausible values\nmath_columns &lt;- stu_qqq_SG[, c(\"PV1MATH\", \"PV2MATH\", \"PV3MATH\", \"PV4MATH\", \"PV5MATH\", \"PV6MATH\", \"PV7MATH\", \"PV8MATH\", \"PV9MATH\", \"PV10MATH\")]\n\n# Calculate the row-wise mean\nmath_row_means &lt;- rowMeans(math_columns)\n\n# Add the row means as a new column to the data frame\nstu_qqq_SG$MATHEMATICS &lt;- math_row_means\n\n\n\n2.5.2 Preparing Reading Data\nSimilarly, upon close examination of the dataset, we have identified that the columns associated with Reading are PV1READ to PV10READ.\nAs a result, we will calculate the average of these plausible values using the rowMeans() function. A new column, labeled READING, will be created to store the resulting average plausible values for the Reading subject.\nThe corresponding code snippet is provided below:\n\n# Select the columns containing read plausible values\nreading_columns &lt;- stu_qqq_SG[, c(\"PV1READ\", \"PV2READ\", \"PV3READ\", \"PV4READ\", \"PV5READ\", \"PV6READ\", \"PV7READ\", \"PV8READ\", \"PV9READ\", \"PV10READ\")]\n\n# Calculate the row-wise mean\nreading_row_means &lt;- rowMeans(reading_columns)\n\n# Add the row means as a new column to the data frame\nstu_qqq_SG$READING &lt;- reading_row_means\n\n\n\n2.5.3 Preparing Science Data\nLastly, upon a thorough review of the dataset, we have determined that the columns corresponding to Science are PV1SCIE to PV10SCIE.\nConsequently, we will use the rowMeans() function to compute the average of these plausible values. A new column, named SCIENCE, will be established to store the resulting average plausible values for the Science subject.\nThe corresponding code snippet is provided below:\n\n# Select the columns containing science plausible values\nscience_columns &lt;- stu_qqq_SG[, c(\"PV1SCIE\", \"PV2SCIE\", \"PV3SCIE\", \"PV4SCIE\", \"PV5SCIE\", \"PV6SCIE\", \"PV7SCIE\", \"PV8SCIE\", \"PV9SCIE\", \"PV10SCIE\")]\n\n# Calculate the row-wise mean\nscience_row_means &lt;- rowMeans(science_columns)\n\n# Add the row means as a new column to the data frame\nstu_qqq_SG$SCIENCE &lt;- science_row_means"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-gender-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-gender-data",
    "title": "Take-home Exercise 1",
    "section": "2.6 Preparing Gender Data",
    "text": "2.6 Preparing Gender Data\nUpon examining the dataset, a particular column labeled ‘ST004D01T’ provides information about gender, using the values 1 and 2. According to the PISA questionnaire manual, 1 corresponds to female, while 2 corresponds to male.\nTo facilitate a more straightforward analysis, we intend to recode the values, assigning 1 to represent female and 2 to represent male. This recoding process will be carried out using the dplyr, a component of the tidyverse package.\nWe prefer generating a new column instead of altering the current one. To achieve this, employ the mutate function in conjunction with the assignment operator (=) to establish a fresh column.\nThis action will introduce a column named ‘GENDER’ into your ‘stu_qqq_SG’ dataset, with values redefined according to the ‘ST004D01T’ column. The original ‘ST004D01T’ column retains its original state, and now, a newly created ‘GENDER’ column contains the recoded values.”\nThe following code snippet provides the pertinent information:\n\n# Install and load the dplyr package if we have not done so\n# install.packages(\"dplyr\")\nlibrary(dplyr)\n\n# Create a new column 'GENDER' with recoded values\nstu_qqq_SG &lt;- stu_qqq_SG %&gt;%\n  mutate(GENDER = recode(ST004D01T, \"1\" = \"female\", \"2\" = \"male\"))\n\nTo check if we have recoded the gender data correctly, we will be displaying the first 10 rows of the GENDER column:\n\nThe outputThe code\n\n\n\n\n# A tibble: 10 × 1\n   GENDER\n   &lt;chr&gt; \n 1 female\n 2 male  \n 3 male  \n 4 male  \n 5 female\n 6 female\n 7 male  \n 8 male  \n 9 female\n10 male  \n\n\n\n\n\nhead(stu_qqq_SG[c(\"GENDER\")],10)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-socioeconomic-status-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-socioeconomic-status-data",
    "title": "Take-home Exercise 1",
    "section": "2.7 Preparing Socioeconomic Status Data",
    "text": "2.7 Preparing Socioeconomic Status Data\nWith reference to the PISA 2022 Technical Report, Figure 5.1 in the PISA 2022 Technical Report illustrates the two-dimensional framework taxonomy. The primary dimension categorises proposed constructs into two overarching categories defined by the PISA Governing Board (PGB): domain-specific constructs and general constructs, with the latter encompassing Economic, Social and Cultural Status (ESCS). The secondary dimension further categorises proposed constructs into five categories based on key areas of educational policy setting at different levels of aggregation. These categories include Student Background, Student Beliefs, Attitudes, Feelings. and Behaviours, Teaching Practices and Learning Opportunities, School Practices, Policies, and Infrastructure, and Governance, System-Level Policies, and Practices.\nTherefore, it can be inferred that the ‘ESCS’ column can be utilised for assessing the socioeconomic status of students.\nIf we view the ‘ESCS’ column, there are negative and positive ESCS values, it generally implies a relative positioning of students along a spectrum of economic, social and cultural advantages or disadvantages.\n\nPositive ESCS value: This typically indicates a higher socioeconomic status, suggesting that the student comes from an environment with more favourable economic conditions, higher social standing, and a richer cultural background. Students with positive ESCS values may have access to more resources, educational support and opportunities.\nNegative ESCS value: Conversely, a negative ESCS value suggests a lower socioeconomic status. Students with negative ESCS values may face economic challenges, have a lower social standing, and possibly experience a less enriched cultural environment. These students may encounter additional obstacles in their educational journey due to a lack of resources or support.\n\nThe first 10 rows of the ESCS column can be seen here:\n\nThe outputThe code\n\n\n\n\n# A tibble: 10 × 1\n      ESCS\n     &lt;dbl&gt;\n 1  0.184 \n 2  0.826 \n 3 -1.04  \n 4 -0.961 \n 5  0.0856\n 6  0.127 \n 7 -0.0154\n 8  1.16  \n 9  1.47  \n10  0.520 \n\n\n\n\n\nhead(stu_qqq_SG[c(\"ESCS\")],10)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-school-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#preparing-school-data",
    "title": "Take-home Exercise 1",
    "section": "2.8 Preparing School Data",
    "text": "2.8 Preparing School Data\nExploring the dataset reveals a sole column dedicated to schools, labeled ‘CNTSCHID.’ Regrettably, the dataset lacks details about the nature of CNTSCHID or the specific identity associated with each school ID. Nonetheless, we must work with the available information as is.\nThe first 10 rows of the CNTSCHID column can be seen here:\n\nThe outputThe code\n\n\n\n\n# A tibble: 10 × 1\n   CNTSCHID\n      &lt;dbl&gt;\n 1 70200052\n 2 70200134\n 3 70200112\n 4 70200004\n 5 70200152\n 6 70200043\n 7 70200049\n 8 70200107\n 9 70200012\n10 70200061\n\n\n\n\n\nhead(stu_qqq_SG[c(\"CNTSCHID\")],10)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#three-subjects---mathematics-reading-and-science",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#three-subjects---mathematics-reading-and-science",
    "title": "Take-home Exercise 1",
    "section": "3.1 Three Subjects - Mathematics, Reading and Science",
    "text": "3.1 Three Subjects - Mathematics, Reading and Science\n\n3.1.1 Distribution Across Three Subjects - Mathematics, Reading and Science\nWe will now do the plot for each respective subject. We will be doing a histogram to show the distribution across three subjects.\nThe code will be shown below:\n\nMathematicsReadingScience\n\n\n\np1 &lt;- ggplot(data=stu_qqq_SG, \n             aes(x = MATHEMATICS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"light blue\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") +\n  geom_vline(xintercept = mean(stu_qqq_SG$MATHEMATICS), \n             color = \"red\", \n             linetype = \"dashed\", \n             size = 1)\n\n\n\n\np2 &lt;- ggplot(data=stu_qqq_SG, \n             aes(x = READING)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"light blue\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Reading scores\") +\n  geom_vline(xintercept = mean(stu_qqq_SG$READING), \n             color = \"red\", \n             linetype = \"dashed\", \n             size = 1)\n\n\n\n\np3 &lt;- ggplot(data=stu_qqq_SG, \n             aes(x = SCIENCE)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"light blue\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Science scores\") +\n  geom_vline(xintercept = mean(stu_qqq_SG$SCIENCE), \n             color = \"red\", \n             linetype = \"dashed\", \n             size = 1) \n\n\n\n\nThe figure in the tabset below displays a composite of three histograms, seamlessly created using patchwork. This is specifically designed for merging separate ggplot2 graphs into a unified figure. The red dotted line indicates the mean.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n\n\n\nThe histogram presented above offers a visual representation of the distribution of scores across three academic subjects: MATHEMATICS, READING and SCIENCE. The distribution pattern observed for each subject strongly aligns with the characteristics of a normal distribution.\nA normal distribution is characterised by a symmetrical bell-shaped curve, with the majority of data points clustering around the mean and gradually tapering off towards the extremes. In the context of academic performance, this implies that a significant proportion of students scored close to the average, while fewer students achieved scores either significantly above or below the mean. In the case of academic assessments, a normal distribution suggests that the difficulty level of the questions was appropriately balanced, allowing for a diverse range of scores among the students.\n\n\n3.1.2 Reading vs Mathematics\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=stu_qqq_SG, \n       aes(x= READING, \n           y=MATHEMATICS)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(150,850),\n                  ylim=c(150,850))\n\n\n\n\nThe scatterplot depicted above illustrates a positive correlation between reading and mathematics values. As the reading values increase, so do the corresponding mathematics values. This relationship is further emphasised by the upward trend observed in the best fit line. The consistent increase in one variable is mirrored by a proportional increase in the other. In light of these findings, it can be confidently asserted that a positive connection exists, suggesting that engaging in reading contributes to enhanced performance in mathematics among students."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#reading-as-our-main-focus",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#reading-as-our-main-focus",
    "title": "Take-home Exercise 1",
    "section": "3.2 “Reading” as our main focus",
    "text": "3.2 “Reading” as our main focus\nWith reference to this research paper titled ‘Reading matters more than mathematics in science learning: an analysis of the relationship between student achievement in reading, mathematics, and science’ by Yuanze Zhu, the results revealed that proficiency in reading and mathematics strongly correlated with science achievement, with reading exerting a more substantial influence than mathematics. Consequently, we assert that prioritising reading over mathematics is essential for enhanced performance in science learning.\nHenceforth, our focus will be exclusively on reading, considering it as the primary driver for improved achievement in other subjects, including Mathematics and Science.\n\n3.2.1 Reading vs Gender\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=stu_qqq_SG, \n       aes(y = READING, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=2)      \n\n\n\n\nWhen it comes to the Reading, females exhibit a higher average performance compared to their male counterparts. The visual representation underscores a clear distinction, suggesting that, on average, females outperform males in the domain of Reading. One plausible interpretation for this observed trend could be rooted in the varying learning styles or preferences between genders. Research has suggested that females may, on average, possess certain cognitive strengths or approaches that align more closely with the skills demanded in Reading tasks. Additionally, sociocultural factors and educational environments may play a role in shaping differential outcomes, influencing how males and females engage with and excel in Reading-related activities.\n\n\n3.2.2 Reading vs Socioeconomic Status (ESCS)\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=stu_qqq_SG, \n       aes(x= READING, y=ESCS)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\n\n\n\nExamining the scatterplot above, it becomes evident that within the reading value range of 200-400, there is minimal correlation with ESCS. During this range, ESCS values exhibit considerable variability, ranging from -3 to 3. However, as reading values surpass 400, ESCS values predominantly hover around 0 and above, indicating a positive relationship. In other words, higher reading values correspond to higher ESCS values. This positive association is further emphasised by the upward trend observed in the best-fit line.\n\n\n3.2.3 Reading vs School ID\nGiven the extensive size of the dataset, our strategy is to concentrate on the top 5 schools that exhibit the highest frequency. Achieving this involves tallying the occurrences of School IDs in the CNTSCHID column.\nTo obtain the counts of each unique CNTSCHID value in descending order, we can use the table() function along with sorting functions.\n\nThe codeThe output\n\n\n\n# Our dataframe is named stu_qqq_SG and the column is CNTSCHID\nschid_counts &lt;- table(stu_qqq_SG$CNTSCHID)\n\n# Convert the result to a data frame and sort in descending order\nschid_counts_df &lt;- as.data.frame(schid_counts)\nschid_counts_df &lt;- schid_counts_df[order(-schid_counts_df$Freq), ]\n\n# Print or use the schid_counts_df as needed\nprint(schid_counts_df)\n\n\n\n\n\n        Var1 Freq\n20  70200020   60\n75  70200075   60\n158 70200159   59\n13  70200013   58\n45  70200045   58\n66  70200066   58\n141 70200141   58\n12  70200012   57\n40  70200040   57\n62  70200062   57\n105 70200105   57\n110 70200110   57\n118 70200118   57\n132 70200132   57\n4   70200004   56\n11  70200011   56\n26  70200026   56\n31  70200031   56\n35  70200035   56\n49  70200049   56\n67  70200067   56\n71  70200071   56\n82  70200082   56\n94  70200094   56\n130 70200130   56\n1   70200001   55\n44  70200044   55\n52  70200052   55\n111 70200111   55\n142 70200142   55\n145 70200145   55\n154 70200155   55\n27  70200027   54\n43  70200043   54\n119 70200119   54\n139 70200139   54\n18  70200018   52\n114 70200114   51\n38  70200038   40\n90  70200090   40\n112 70200112   40\n128 70200128   40\n150 70200151   40\n161 70200162   40\n17  70200017   39\n19  70200019   39\n29  70200029   39\n53  70200053   39\n59  70200059   39\n61  70200061   39\n63  70200063   39\n65  70200065   39\n68  70200068   39\n84  70200084   39\n104 70200104   39\n106 70200106   39\n131 70200131   39\n137 70200137   39\n164 70200165   39\n2   70200002   38\n5   70200005   38\n7   70200007   38\n8   70200008   38\n25  70200025   38\n36  70200036   38\n64  70200064   38\n73  70200073   38\n92  70200092   38\n93  70200093   38\n116 70200116   38\n126 70200126   38\n134 70200134   38\n140 70200140   38\n146 70200146   38\n151 70200152   38\n16  70200016   37\n21  70200021   37\n22  70200022   37\n32  70200032   37\n39  70200039   37\n42  70200042   37\n46  70200046   37\n47  70200047   37\n74  70200074   37\n76  70200076   37\n80  70200080   37\n85  70200085   37\n86  70200086   37\n87  70200087   37\n108 70200108   37\n117 70200117   37\n120 70200120   37\n121 70200121   37\n127 70200127   37\n135 70200135   37\n136 70200136   37\n144 70200144   37\n152 70200153   37\n155 70200156   37\n162 70200163   37\n163 70200164   37\n3   70200003   36\n6   70200006   36\n9   70200009   36\n10  70200010   36\n14  70200014   36\n24  70200024   36\n34  70200034   36\n37  70200037   36\n48  70200048   36\n51  70200051   36\n54  70200054   36\n58  70200058   36\n70  70200070   36\n81  70200081   36\n83  70200083   36\n88  70200088   36\n89  70200089   36\n96  70200096   36\n99  70200099   36\n102 70200102   36\n103 70200103   36\n109 70200109   36\n122 70200122   36\n125 70200125   36\n129 70200129   36\n143 70200143   36\n159 70200160   36\n160 70200161   36\n23  70200023   35\n55  70200055   35\n77  70200077   35\n91  70200091   35\n97  70200097   35\n101 70200101   35\n107 70200107   35\n133 70200133   35\n153 70200154   35\n15  70200015   34\n72  70200072   34\n98  70200098   34\n100 70200100   34\n113 70200113   34\n156 70200157   34\n33  70200033   33\n56  70200056   33\n69  70200069   33\n115 70200115   33\n123 70200123   32\n124 70200124   32\n79  70200079   31\n148 70200148   31\n30  70200030   30\n50  70200050   30\n147 70200147   30\n60  70200060   29\n157 70200158   29\n57  70200057   28\n95  70200095   28\n149 70200149   28\n28  70200028   22\n78  70200078   22\n138 70200138   15\n41  70200041    5\n\n\n\n\n\nFrom the output, we can see that the top 5 School IDs are:\n\n70200020\n70200075\n70200159\n70200013\n70200045\n\nTherefore, we will only focus on the above mentioned School IDs for our analysis.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Filter the data for specific values of CNTSCHID\nfiltered_data &lt;- stu_qqq_SG %&gt;%\n  filter(CNTSCHID %in% c(70200020, 70200075, 70200159, 70200013, 70200045))\n\n# Convert CNTSCHID to factor\nfiltered_data$CNTSCHID &lt;- as.factor(filtered_data$CNTSCHID)\n\n# Create the plot with the filtered data\nggplot(data = filtered_data, \n       aes(y = READING, x = CNTSCHID)) +\n  geom_boxplot() +\n  geom_point(stat = \"summary\",        \n             fun.y = \"mean\",           \n             colour = \"red\",          \n             size = 2)\n\n\n\n\nUpon a detailed analysis of the boxplot, which visually encapsulates the distribution of Reading plausible values across multiple schools (identified by CNTSCHID), a distinct trend emerges. Notably, CNTSCHID 70200020, representing a specific school within the dataset, stands out with the highest mean Reading score, hovering around an impressive ~630. This observation sheds light on the academic performance of this particular school, suggesting a noteworthy level of achievement in Reading compared to the other four schools. The boxplot serves as a valuable tool in visually conveying these distributional nuances, highlighting the academic prowess of CNTSCHID 70200020 within the context of Reading achievement among the schools."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "This chapter introduces fundamental principles and key elements of ggplot2. We will simultaneously acquire practical skills in utilising these elements to generate statistical graphics, following the principles of the Layered Grammar of Graphics. By the conclusion of this chapter, we will have the ability to employ ggplot2’s essential graphical components to craft sophisticated and functional statistical visuals."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "1.2.1 Install and launching R packages",
    "text": "1.2.1 Install and launching R packages\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "1.2.2 Importing the data",
    "text": "1.2.2 Importing the data\nWe bring exam_data.csv into the R environment using the read.csv() function and then assign it to the variable exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nIn R, the conventional format for creating objects and assignment statements is as follows:\n\nobject_name &lt;- value\n\nWe can use glimpse( ) and summary( ) to quickly inspect exam_data.\n\nglimpse(exam_data)\n\nRows: 322\nColumns: 7\n$ ID      &lt;chr&gt; \"Student321\", \"Student305\", \"Student289\", \"Student227\", \"Stude…\n$ CLASS   &lt;chr&gt; \"3I\", \"3I\", \"3H\", \"3F\", \"3I\", \"3I\", \"3I\", \"3I\", \"3I\", \"3H\", \"3…\n$ GENDER  &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"M…\n$ RACE    &lt;chr&gt; \"Malay\", \"Malay\", \"Chinese\", \"Chinese\", \"Malay\", \"Malay\", \"Chi…\n$ ENGLISH &lt;dbl&gt; 21, 24, 26, 27, 27, 31, 31, 31, 33, 34, 34, 36, 36, 36, 37, 38…\n$ MATHS   &lt;dbl&gt; 9, 22, 16, 77, 11, 16, 21, 18, 19, 49, 39, 35, 23, 36, 49, 30,…\n$ SCIENCE &lt;dbl&gt; 15, 16, 16, 31, 25, 16, 25, 27, 15, 37, 42, 22, 32, 36, 35, 45…\n\n\n\nsummary(exam_data)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "title": "Hands-on Exercise 1",
    "section": "1.31 R Graphics vs ggplot",
    "text": "1.31 R Graphics vs ggplot\nLet’s examine the differences in how R Graphics, encompassing the fundamental graphical functions of Base R, and ggplot2, create a basic histogram.\n\nBase Rggplot\n\n\n\nhist(exam_data$MATHS, col = '#5e82c9')\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill='#5e82c9') +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nWhile the code is more straightforward with R Graphics, Hadley Wickham emphasises that the valuable skills gained from ggplot2 extend beyond mere plotting syntax. Instead, they involve adopting a potent mindset for visualization, considering it as a method to map between variables and the visual characteristics of geometric objects that are perceptible.\n\n\n\n\n\n\nImportant\n\n\n\nThe transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-bar-chart",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-bar-chart",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a simple bar chart",
    "text": "Plotting a simple bar chart\n\nggplot(data = exam_data, \n      aes(x = RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_bar",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_bar",
    "title": "Hands-on Exercise 1",
    "section": "1.7.1 Geometric Objects: geom_bar()",
    "text": "1.7.1 Geometric Objects: geom_bar()\nThe code chunk below plots a bar chart by using geom_bar(https://ggplot2.tidyverse.org/reference/geom_bar.html).\naes(x=RACE) defines “RACE” as the x-axis.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_dotplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_dotplot",
    "title": "Hands-on Exercise 1",
    "section": "1.7.2 Geometric Objects: geom_dotplot()",
    "text": "1.7.2 Geometric Objects: geom_dotplot()\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nBelow, we use geom_dotplot() to plot a dot plot of math scores.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis,\nand binwidth argument is used to change the binwidth to 2.5.\n\n\n\nWe insert 2 additional arguments in geom_dotplot()\n\n‘binwidth’ which refers to group ranges\n‘dotsize’ which scales the size of the dots.\n\nThe function scale_y_continuous() is also added to turn off the y-axis by setting it to NULL.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5,\n               color=\"black\", \n               fill='#5e82c9') +\n  scale_y_continuous(NULL,           \n                     breaks = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_histogram",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_histogram",
    "title": "Hands-on Exercise 1",
    "section": "1.7.3 Geometric Objects: geom_histogram()",
    "text": "1.7.3 Geometric Objects: geom_histogram()\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the default bin is 30."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "title": "Hands-on Exercise 1",
    "section": "1.7.4 Modifying a geometric object by changing geom()",
    "text": "1.7.4 Modifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "title": "Hands-on Exercise 1",
    "section": "1.7.5 Modifying a geometric object by changing aes",
    "text": "1.7.5 Modifying a geometric object by changing aes\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom-density",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom-density",
    "title": "Hands-on Exercise 1",
    "section": "1.7.6 Geometric objects: geom-density()",
    "text": "1.7.6 Geometric objects: geom-density()\ngeom-density computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "title": "Hands-on Exercise 1",
    "section": "1.7.7 Geometric objects: geom_boxplot",
    "text": "1.7.7 Geometric objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually. The code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_viloin",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_viloin",
    "title": "Hands-on Exercise 1",
    "section": "1.7.8 Geometric objects: geom_viloin",
    "text": "1.7.8 Geometric objects: geom_viloin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "title": "Hands-on Exercise 1",
    "section": "1.7.9 Geometric objects: geom_point()",
    "text": "1.7.9 Geometric objects: geom_point()\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point-1",
    "title": "Hands-on Exercise 1",
    "section": "1.7.10 Geometric objects: geom_point()",
    "text": "1.7.10 Geometric objects: geom_point()\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat",
    "title": "Hands-on Exercise 1",
    "section": "1.8.1 Working with stat()",
    "text": "1.8.1 Working with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "title": "Hands-on Exercise 1",
    "section": "1.8.2 Working with stat - the stat_summary() method",
    "text": "1.8.2 Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "title": "Hands-on Exercise 1",
    "section": "1.8.3 Working with stat - the geom() method",
    "text": "1.8.3 Working with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "title": "Hands-on Exercise 1",
    "section": "1.8.4 Adding a best fit curve on a scatterplot?",
    "text": "1.8.4 Adding a best fit curve on a scatterplot?\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point()\n\n\n\n\n\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe default method used is loess.\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "title": "Hands-on Exercise 1",
    "section": "1.9.1 Working with facet_wrap()",
    "text": "1.9.1 Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_grid-function",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_grid-function",
    "title": "Hands-on Exercise 1",
    "section": "1.9.2 facet_grid() function",
    "text": "1.9.2 facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-coordinate",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-coordinate",
    "title": "Hands-on Exercise 1",
    "section": "1.10.1 Working with Coordinate",
    "text": "1.10.1 Working with Coordinate\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range",
    "title": "Hands-on Exercise 1",
    "section": "1.10.2 Changing the y- and x-axis range",
    "text": "1.10.2 Changing the y- and x-axis range\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n\n\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-theme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-theme",
    "title": "Hands-on Exercise 1",
    "section": "1.11.1 Working with theme",
    "text": "1.11.1 Working with theme\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.2.1 Installing and launching R packages",
    "text": "8.2.1 Installing and launching R packages\nDuring this hands on tutorial, we will install and initiate four key packages for network data modeling and visualisation: igraph, tidygraph, ggraph, and visNetwork. In addition to these, the tidyverse suite and lubridate, an R package specifically designed for managing and manipulating time-based data, will also be installed and activated.\nHere’s the code snippet:\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-edges-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-edges-data",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.3.1 The edges data",
    "text": "8.3.1 The edges data\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-nodes-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-nodes-data",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.3.2 The nodes data",
    "text": "8.3.2 The nodes data\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-network-data-from-files",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-network-data-from-files",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.3.3 Importing network data from files",
    "text": "8.3.3 Importing network data from files\nIn this step, we will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reviewing-the-imported-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reviewing-the-imported-data",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.3.4 Reviewing the imported data",
    "text": "8.3.4 Reviewing the imported data\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#wrangling-time",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#wrangling-time",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.3.5 Wrangling time",
    "text": "8.3.5 Wrangling time\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reviewing-the-revised-date-fields",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reviewing-the-revised-date-fields",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.3.6 Reviewing the revised date fields",
    "text": "8.3.6 Reviewing the revised date fields\nTable below shows the data structure of the reformatted GAStech_edges data frame"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#wrangling-attributes",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#wrangling-attributes",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.3.7 Wrangling attributes",
    "text": "8.3.7 Wrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reviewing-the-revised-edges-file",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reviewing-the-revised-edges-file",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.3.8 Reviewing the revised edges file",
    "text": "8.3.8 Reviewing the revised edges file\nTable below shows the data structure of the reformatted GAStech_edges data frame"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-tbl_graph-object",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-tbl_graph-object",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.4.1 The tbl_graph object",
    "text": "8.4.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network.\n\nBelow are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-dplyr-verbs-in-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-dplyr-verbs-in-tidygraph",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.4.2 The dplyr verbs in tidygraph",
    "text": "8.4.2 The dplyr verbs in tidygraph\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#using-tbl_graph-to-build-tidygraph-data-model.",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#using-tbl_graph-to-build-tidygraph-data-model.",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.4.3 Using tbl_graph() to build tidygraph data model.",
    "text": "8.4.3 Using tbl_graph() to build tidygraph data model.\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reviewing-the-output-tidygraphs-graph-object",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reviewing-the-output-tidygraphs-graph-object",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.4.4 Reviewing the output tidygraph’s graph object",
    "text": "8.4.4 Reviewing the output tidygraph’s graph object\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reviewing-the-output-tidygraphs-graph-object-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reviewing-the-output-tidygraphs-graph-object-1",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.4.5 Reviewing the output tidygraph’s graph object",
    "text": "8.4.5 Reviewing the output tidygraph’s graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#changing-the-active-object",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#changing-the-active-object",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.4.6 Changing the active object",
    "text": "8.4.6 Changing the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plotting-a-basic-network-graph",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plotting-a-basic-network-graph",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.5.1 Plotting a basic network graph",
    "text": "8.5.1 Plotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#changing-the-default-network-graph-theme",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#changing-the-default-network-graph-theme",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.5.2 Changing the default network graph theme",
    "text": "8.5.2 Changing the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#changing-the-coloring-of-the-plot",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#changing-the-coloring-of-the-plot",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.5.3 Changing the coloring of the plot",
    "text": "8.5.3 Changing the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-ggraphs-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-ggraphs-layouts",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.5.4 Working with ggraph’s layouts",
    "text": "8.5.4 Working with ggraph’s layouts\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#fruchterman-and-reingold-layout",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#fruchterman-and-reingold-layout",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.5.5 Fruchterman and Reingold layout",
    "text": "8.5.5 Fruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#modifying-network-nodes",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#modifying-network-nodes",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.5.6 Modifying network nodes",
    "text": "8.5.6 Modifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#modifying-edges",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#modifying-edges",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.5.7 Modifying edges",
    "text": "8.5.7 Modifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-facet_edges",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-facet_edges",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.6.1 Working with facet_edges()",
    "text": "8.6.1 Working with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-facet_edges-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-facet_edges-1",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.6.2 Working with facet_edges()",
    "text": "8.6.2 Working with facet_edges()\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#a-framed-facet-graph",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#a-framed-facet-graph",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.6.3 A framed facet graph",
    "text": "8.6.3 A framed facet graph\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-facet_nodes",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-facet_nodes",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.6.4 Working with facet_nodes()",
    "text": "8.6.4 Working with facet_nodes()\nIn the code chunk below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-centrality-indices",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-centrality-indices",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.7.1 Computing centrality indices",
    "text": "8.7.1 Computing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-network-metrics",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-network-metrics",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.7.2 Visualising network metrics",
    "text": "8.7.2 Visualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-community",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-community",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.7.3 Visualising Community",
    "text": "8.7.3 Visualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#data-preparation",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.8.1 Data preparation",
    "text": "8.8.1 Data preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plotting-the-first-interactive-network-graph",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plotting-the-first-interactive-network-graph",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.8.2 Plotting the first interactive network graph",
    "text": "8.8.2 Plotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-layout",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-layout",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.8.3 Working with layout",
    "text": "8.8.3 Working with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-visual-attributes---nodes",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-visual-attributes---nodes",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.8.4 Working with visual attributes - Nodes",
    "text": "8.8.4 Working with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-visual-attributes---edges",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#working-with-visual-attributes---edges",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.8.5 Working with visual attributes - Edges",
    "text": "8.8.5 Working with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n\nThe argument arrows is used to define where to place the arrow.\nThe smooth argument is used to plot the edges using a smooth curve.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#interactivity",
    "title": "Hands-on Exercise 8: Network Data Visualisation and Analysis",
    "section": "8.8.6 Interactivity",
    "text": "8.8.6 Interactivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.3.1 The Data",
    "text": "7.3.1 The Data\nTo create the choropleth map, we will use two datasets:\n\nThe “Master Plan 2014 Subzone Boundary (Web)” (abbreviated as MP14_SUBZONE_WEB_PL), available in ESRI shapefile format. This geospatial dataset outlines the geographical boundaries of Singapore at the planning subzone level, based on the Urban Redevelopment Authority’s Master Plan 2014. It is accessible for download from data.gov.sg.\n“Singapore Residents by Planning Area/Subzone, Age Group, Sex, and Type of Dwelling, June 2011-2020” in CSV format (file name: respopagesextod2011to2020.csv). This dataset, which can be downloaded from the Department of Statistics, Singapore, is considered aspatial, meaning it lacks coordinate values. However, its PA and SZ fields serve as unique identifiers that allow for geocoding to the MP14_SUBZONE_WEB_PL shapefile."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-the-data",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.3.2 Importing the data",
    "text": "7.3.2 Importing the data\nThe following code snippet employs the st_read() function from the sf package to load the MP14_SUBZONE_WEB_PL shapefile into R, where it is stored as a simple feature data frame named mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/rizfebriansyah/GitHub/ISSS608-VAA/Hands-on_Ex/Hands-on_Ex07/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-attribute-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-attribute-data-into-r",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.3.3 Importing Attribute Data into R",
    "text": "7.3.3 Importing Attribute Data into R\nFollowing this, we’ll proceed to load the respopagsex2011to2020.csv file into RStudio, storing it in an R dataframe named popagsex.\nThis operation will be executed using the read_csv() function from the readr package, as illustrated in the code snippet below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-preparation",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.3.4 Data Preparation",
    "text": "7.3.4 Data Preparation\nBefore creating a thematic map, it is necessary to compile a data table focusing on the year 2020. This table needs to encompass several variables: PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG refers to the population in the age groups from 0-4 up to 20-24.\nECONOMY ACTIVE encompasses individuals in the age groups from 25-29 to 60-64.\nAGED includes those aged 65 and above.\nTOTAL represents the sum of all age groups.\nDEPENDENCY calculates the ratio of the sum of YOUNG and AGED populations to the ECONOMY ACTIVE population.\n\n\n7.3.4.1 Data Wrangling\nThe data manipulation and transformation tasks will involve the use of the following functions:\n\npivot_wider() from the tidyr package, and\nmutate(), filter(), group_by(), and select() from the dplyr package.\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n7.3.4.2 Joining the attribute data and geospatial data\nBefore proceeding with the georelational join, we must undertake an additional step of converting the values in the PA and SZ fields to uppercase. This step is necessary due to the mixed use of upper- and lowercase letters in the PA and SZ fields, whereas the SUBZONE_N and PLN_AREA_N fields are consistently in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nKey takeaway from the above code snippet:\nThe left_join() function from the dplyr package is applied, with the mpsz simple feature data frame designated as the left table. This approach guarantees that the resulting output will maintain its structure as a simple features data frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.4.1 Plotting a choropleth map quickly by using qtm()",
    "text": "7.4.1 Plotting a choropleth map quickly by using qtm()\nThe simplest and fastest way to create a choropleth map with tmap is through the use of qtm(). This approach is straightforward and often yields a visually appealing default representation.\nBelow, the code snippet will produce a choropleth map adhering to cartographic standards.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nKey insights from the provided code snippet include:\n\nThe function tmap_mode() is utilised with the option “plot” to generate a static map. To create an interactive map, the “view” option would be selected.\nThe fill parameter is employed to visually represent a specific attribute, in this case, “DEPENDENCY”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.4.2 Creating a choropleth map by using tmap’s elements",
    "text": "7.4.2 Creating a choropleth map by using tmap’s elements\nWhile qtm() offers a convenient and quick way to produce a choropleth map, its drawback lies in the limited control over the aesthetics of individual layers. For creating a high-quality cartographic choropleth map, as illustrated in the figure below, it’s recommended to utilise the drawing elements provided by tmap.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#drawing-a-base-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#drawing-a-base-map",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.4.2.1 Drawing a base map",
    "text": "7.4.2.1 Drawing a base map\nThe fundamental component of tmap is the tm_shape() function, which is then complemented by one or more layer elements like tm_fill() and tm_polygons().\nIn the following code snippet, tm_shape() specifies the input data (i.e., mpsz_pop2020), and tm_polygons() is employed to render the polygons of the planning subzones.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#drawing-a-choropleth-map-using-tm_polygons",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#drawing-a-choropleth-map-using-tm_polygons",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.4.2.2 Drawing a choropleth map using tm_polygons()",
    "text": "7.4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3. The default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4. By default, Missing value will be shaded in grey."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#drawing-a-choropleth-map-using-tm_fill-and-tm_border",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#drawing-a-choropleth-map-using-tm_fill-and-tm_border",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.4.2.3 Drawing a choropleth map using tm_fill() and tm_border()",
    "text": "7.4.2.3 Drawing a choropleth map using tm_fill() and tm_border()\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\ncol = border colour, lwd = border line width. The default is 1, and lty = border line type. The default is “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#colour-scheme",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.4.4 Colour Scheme",
    "text": "7.4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n7.4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#map-layouts",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.4.5 Map Layouts",
    "text": "7.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n7.4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n7.4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n7.4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#drawing-small-multiple-choropleth-maps",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "7.4.6 Drawing Small Multiple Choropleth Maps",
    "text": "7.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n7.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n7.4.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n7.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#geting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#geting-started",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "Geting Started",
    "text": "Geting Started\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#the-data-1",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "8.2.1 The data",
    "text": "8.2.1 The data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-import-and-preparation",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "8.2.2 Data Import and Preparation",
    "text": "8.2.2 Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#it-all-started-with-an-interactive-point-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#it-all-started-with-an-interactive-point-symbol-map",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "8.4.1 It all started with an interactive point symbol map",
    "text": "8.4.1 It all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#lets-make-it-proportional",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#lets-make-it-proportional",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "8.4.2 Lets make it proportional",
    "text": "8.4.2 Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#lets-give-it-a-different-colour",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#lets-give-it-a-different-colour",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "8.4.3 Lets give it a different colour",
    "text": "8.4.3 Lets give it a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcomes",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "9.1.1 Learning Outcomes",
    "text": "9.1.1 Learning Outcomes\nThis hands-on exercise is designed to provide us with practical experience in applying the relevant R techniques for mapping analysis. Upon completing this hands-on exercise, we will have the skills to utilise specific functions from tmap and tidyverse to accomplish the tasks below:\n\nImporting geospatial data in rds format into the R environment.\nGenerating choropleth maps of cartographic quality with suitable tmap functions.\nDeveloping a rate map.\nProducing a percentile map.\nConstructing a boxmap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#installing-and-loading-packages",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "9.2.1 Installing and loading packages",
    "text": "9.2.1 Installing and loading packages\n\npacman::p_load(tmap, tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-data",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "9.2.2 Importing data",
    "text": "9.2.2 Importing data\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualising-distribution-of-non-functional-water-point",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualising-distribution-of-non-functional-water-point",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "9.3.1 Visualising distribution of non-functional water point",
    "text": "9.3.1 Visualising distribution of non-functional water point\nLet’s plot a choropleth map showing the distribution of non-function water point by LGA\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "9.4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points",
    "text": "9.4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-map-of-rate",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-map-of-rate",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "9.4.2 Plotting map of rate",
    "text": "9.4.2 Plotting map of rate\nLet’s plot a choropleth map showing the distribution of percentage functional water point by LGA\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#percentile-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#percentile-map",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "9.5.1 Percentile Map",
    "text": "9.5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n9.5.1.1 Data Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\n9.5.1.2 Why writing functions?\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n9.5.1.3 Creating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n9.5.1.4 A percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n9.5.1.5 Test drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#box-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#box-map",
    "title": "Hands-on Exercise 7: Visualising and Analysing Geographic Data",
    "section": "9.5.2 Box map",
    "text": "9.5.2 Box map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n9.5.2.1 Creating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n9.5.2.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n9.5.2.3 Test drive the newly created function\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n9.5.2.4 Boxmap function\nThe code chunk below is an R function to create a box map.\n\narguments\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nreturns\n\na tmap-element (plots a map)\n\n\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#our-dataset",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#our-dataset",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "5.3.1 Our dataset",
    "text": "5.3.1 Our dataset\nIn this practical exercise, we will utilise the dataset titled “Singapore Residents by Planning Area/Subzone, Age Group, Sex, and Type of Dwelling, June 2000-2018.” This dataset has already been downloaded and is stored in the ‘data’ sub-folder within the exercise folder. The file is named respopagsex2000to2018_tidy.csv and is available in CSV format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-data",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "5.3.2 Importing Data",
    "text": "5.3.2 Importing Data\nTo import ‘respopagsex2000to2018_tidy.csv’ into R, read_csv() function of readr package will be used.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#preparing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#preparing-the-data",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "5.3.3 Preparing the Data",
    "text": "5.3.3 Preparing the Data\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-a-static-ternary-diagram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-a-static-ternary-diagram",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "5.4.1 Plotting a static ternary diagram",
    "text": "5.4.1 Plotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-an-interactive-ternary-diagram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-an-interactive-ternary-diagram",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "5.4.2 Plotting an interactive ternary diagram",
    "text": "5.4.2 Plotting an interactive ternary diagram\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#importing-data",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.3.1 Importing Data",
    "text": "6.3.1 Importing Data\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#building-a-basic-correlation-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#building-a-basic-correlation-matrix",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.4.1 Building a basic correlation matrix",
    "text": "6.4.1 Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#drawing-the-lower-corner",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#drawing-the-lower-corner",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.4.2 Drawing the lower corner",
    "text": "6.4.2 Drawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#including-with-correlation-coefficients",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#including-with-correlation-coefficients",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.4.3 Including with correlation coefficients",
    "text": "6.4.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#the-basic-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#the-basic-plot",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.5.1 The basic plot",
    "text": "6.5.1 The basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#getting-started-with-corrplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#getting-started-with-corrplot",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.7.1 Getting started with corrplot",
    "text": "6.7.1 Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-visual-geometrics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-visual-geometrics",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.7.2 Working with visual geometrics",
    "text": "6.7.2 Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\nFeel free to change the method argument to other supported visual geometrics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-layout",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-layout",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.7.3 Working with layout",
    "text": "6.7.3 Working with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-mixed-layout",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-mixed-layout",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.7.4 Working with mixed layout",
    "text": "6.7.4 Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#combining-corrgram-with-the-significant-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#combining-corrgram-with-the-significant-test",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.7.5 Combining corrgram with the significant test",
    "text": "6.7.5 Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\n\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#reorder-a-corrgram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#reorder-a-corrgram",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.7.6 Reorder a corrgram",
    "text": "6.7.6 Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#reordering-a-correlation-matrix-using-hclust",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#reordering-a-correlation-matrix-using-hclust",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "6.7.7 Reordering a correlation matrix using hclust",
    "text": "6.7.7 Reordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#importing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#importing-the-data-set",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.3.1 Importing the data set",
    "text": "7.3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#preparing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#preparing-the-data",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.3.2 Preparing the data",
    "text": "7.3.2 Preparing the data\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#transforming-the-data-frame-into-a-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#transforming-the-data-frame-into-a-matrix",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.3.3 Transforming the data frame into a matrix",
    "text": "7.3.3 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#heatmap-of-r-stats",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#heatmap-of-r-stats",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.4.1 heatmap() of R Stats",
    "text": "7.4.1 heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote: By default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote: The order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-heatmaply",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-heatmaply",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.5.1 Working with heatmaply",
    "text": "7.5.1 Working with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#data-trasformation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#data-trasformation",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.5.2 Data trasformation",
    "text": "7.5.2 Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n7.5.2.1 Scaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columnwise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n7.5.2.2 Normalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n7.5.2.3 Percentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#clustering-algorithm",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#clustering-algorithm",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.5.3 Clustering algorithm",
    "text": "7.5.3 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#manual-approach",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#manual-approach",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.5.4 Manual approach",
    "text": "7.5.4 Manual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#statistical-approach",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#statistical-approach",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.5.5 Statistical approach",
    "text": "7.5.5 Statistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#seriation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#seriation",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.5.6 Seriation",
    "text": "7.5.6 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-colour-palettes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-colour-palettes",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.5.7 Working with colour palettes",
    "text": "7.5.7 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#the-finishing-touch",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#the-finishing-touch",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "7.5.8 The finishing touch",
    "text": "7.5.8 The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsize_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#plotting-a-simple-parallel-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#plotting-a-simple-parallel-coordinates",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "8.4.1 Plotting a simple parallel coordinates",
    "text": "8.4.1 Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#plotting-a-parallel-coordinates-with-boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#plotting-a-parallel-coordinates-with-boxplot",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "8.4.2 Plotting a parallel coordinates with boxplot",
    "text": "8.4.2 Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#parallel-coordinates-with-facet",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#parallel-coordinates-with-facet",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "8.4.3 Parallel coordinates with facet",
    "text": "8.4.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#rotating-x-axis-text-label",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#rotating-x-axis-text-label",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "8.4.4 Rotating x-axis text label",
    "text": "8.4.4 Rotating x-axis text label\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below:\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#adjusting-the-rotated-x-axis-text-label",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#adjusting-the-rotated-x-axis-text-label",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "8.4.5 Adjusting the rotated x-axis text label",
    "text": "8.4.5 Adjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#the-basic-plot-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#the-basic-plot-1",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "8.5.1 The basic plot",
    "text": "8.5.1 The basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#rotate-axis-label",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#rotate-axis-label",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "8.5.2 Rotate axis label",
    "text": "8.5.2 Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#changing-the-colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#changing-the-colour-scheme",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "8.5.3 Changing the colour scheme",
    "text": "8.5.3 Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunk below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#parallel-coordinates-plot-with-histogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#parallel-coordinates-plot-with-histogram",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "8.5.4 Parallel coordinates plot with histogram",
    "text": "8.5.4 Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#importing-the-data-set-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#importing-the-data-set-1",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.3.1 Importing the data set",
    "text": "9.3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nThe output tibble data.frame is called realis2018."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#data-wrangling-and-manipulation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#data-wrangling-and-manipulation",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.3.2 Data Wrangling and Manipulation",
    "text": "9.3.2 Data Wrangling and Manipulation\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\n\n\n\n\nRecommendation\n\n\n\nStudents who are new to dplyr methods should consult Introduction to dplyr before moving on to the next section."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#grouped-summaries-without-the-pipe",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#grouped-summaries-without-the-pipe",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.3.3 Grouped summaries without the Pipe",
    "text": "9.3.3 Grouped summaries without the Pipe\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\n\n\nNote\n\n\n\nAggregation functions such as sum() and meadian() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#grouped-summaries-with-the-pipe",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#grouped-summaries-with-the-pipe",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.3.4 Grouped summaries with the pipe",
    "text": "9.3.4 Grouped summaries with the pipe\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\n\n\n\n\n\nRecommendation\n\n\n\nTo learn more about pipe, visit this excellent article: Pipes in R Tutorial For Beginners.\n\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#designing-a-static-treemap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#designing-a-static-treemap",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.4.1 Designing a static treemap",
    "text": "9.4.1 Designing a static treemap\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#using-the-basic-arguments",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#using-the-basic-arguments",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.4.2 Using the basic arguments",
    "text": "9.4.2 Using the basic arguments\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\n\n\n\n\n\n\nWarning:\n\n\n\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-vcolor-and-type-arguments",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-vcolor-and-type-arguments",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.4.3 Working with vColor and type arguments",
    "text": "9.4.3 Working with vColor and type arguments\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#colours-in-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#colours-in-treemap-package",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.4.4 Colours in treemap package",
    "text": "9.4.4 Colours in treemap package\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#the-value-type-treemap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#the-value-type-treemap",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.4.5 The “value” type treemap",
    "text": "9.4.5 The “value” type treemap\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nAlthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#the-manual-type-treemap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#the-manual-type-treemap",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.4.6 The “manual” type treemap",
    "text": "9.4.6 The “manual” type treemap\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#treemap-layout",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#treemap-layout",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.4.7 Treemap Layout",
    "text": "9.4.7 Treemap Layout\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-algorithm-argument",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#working-with-algorithm-argument",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.4.8 Working with algorithm argument",
    "text": "9.4.8 Working with algorithm argument\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#using-sortid",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#using-sortid",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.4.9 Using sortID",
    "text": "9.4.9 Using sortID\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#designing-a-basic-treemap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#designing-a-basic-treemap",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.5.1 Designing a basic treemap",
    "text": "9.5.1 Designing a basic treemap\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#defining-hierarchy",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#defining-hierarchy",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.5.2 Defining hierarchy",
    "text": "9.5.2 Defining hierarchy\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#installing-d3treer-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#installing-d3treer-package",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.6.1 Installing d3treeR package",
    "text": "9.6.1 Installing d3treeR package\nThis slide shows you how to install a R package which is not available in cran.\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\n\ninstall.packages(\"devtools\")\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\n\nNow you are ready to launch d3treeR package\n\nlibrary(d3treeR)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#designing-an-interactive-treemap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05p2.html#designing-an-interactive-treemap",
    "title": "Hands-on Exercise 5: Visual Multivariate Analysis",
    "section": "9.6.2 Designing An Interactive Treemap",
    "text": "9.6.2 Designing An Interactive Treemap\nThe codes below perform two processes.\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\nd3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.2.1 Installing and launching R packages",
    "text": "8.2.1 Installing and launching R packages\nDuring this hands on tutorial, we will install and initiate four key packages for network data modeling and visualisation: igraph, tidygraph, ggraph, and visNetwork. In addition to these, the tidyverse suite and lubridate, an R package specifically designed for managing and manipulating time-based data, will also be installed and activated.\nHere’s the code snippet:\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#the-edges-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#the-edges-data",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.3.1 The edges data",
    "text": "8.3.1 The edges data\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#the-nodes-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#the-nodes-data",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.3.2 The nodes data",
    "text": "8.3.2 The nodes data\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#importing-network-data-from-files",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#importing-network-data-from-files",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.3.3 Importing network data from files",
    "text": "8.3.3 Importing network data from files\nIn this step, we will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reviewing-the-imported-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reviewing-the-imported-data",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.3.4 Reviewing the imported data",
    "text": "8.3.4 Reviewing the imported data\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#wrangling-time",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#wrangling-time",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.3.5 Wrangling time",
    "text": "8.3.5 Wrangling time\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reviewing-the-revised-date-fields",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reviewing-the-revised-date-fields",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.3.6 Reviewing the revised date fields",
    "text": "8.3.6 Reviewing the revised date fields\nTable below shows the data structure of the reformatted GAStech_edges data frame"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#wrangling-attributes",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#wrangling-attributes",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.3.7 Wrangling attributes",
    "text": "8.3.7 Wrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reviewing-the-revised-edges-file",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reviewing-the-revised-edges-file",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.3.8 Reviewing the revised edges file",
    "text": "8.3.8 Reviewing the revised edges file\nTable below shows the data structure of the reformatted GAStech_edges data frame"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#the-tbl_graph-object",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#the-tbl_graph-object",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.4.1 The tbl_graph object",
    "text": "8.4.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network.\n\nBelow are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#the-dplyr-verbs-in-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#the-dplyr-verbs-in-tidygraph",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.4.2 The dplyr verbs in tidygraph",
    "text": "8.4.2 The dplyr verbs in tidygraph\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#using-tbl_graph-to-build-tidygraph-data-model.",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#using-tbl_graph-to-build-tidygraph-data-model.",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.4.3 Using tbl_graph() to build tidygraph data model.",
    "text": "8.4.3 Using tbl_graph() to build tidygraph data model.\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reviewing-the-output-tidygraphs-graph-object",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reviewing-the-output-tidygraphs-graph-object",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.4.4 Reviewing the output tidygraph’s graph object",
    "text": "8.4.4 Reviewing the output tidygraph’s graph object\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reviewing-the-output-tidygraphs-graph-object-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reviewing-the-output-tidygraphs-graph-object-1",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.4.5 Reviewing the output tidygraph’s graph object",
    "text": "8.4.5 Reviewing the output tidygraph’s graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-active-object",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-active-object",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.4.6 Changing the active object",
    "text": "8.4.6 Changing the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-a-basic-network-graph",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-a-basic-network-graph",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.5.1 Plotting a basic network graph",
    "text": "8.5.1 Plotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-default-network-graph-theme",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-default-network-graph-theme",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.5.2 Changing the default network graph theme",
    "text": "8.5.2 Changing the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-coloring-of-the-plot",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#changing-the-coloring-of-the-plot",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.5.3 Changing the coloring of the plot",
    "text": "8.5.3 Changing the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-ggraphs-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-ggraphs-layouts",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.5.4 Working with ggraph’s layouts",
    "text": "8.5.4 Working with ggraph’s layouts\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#fruchterman-and-reingold-layout",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#fruchterman-and-reingold-layout",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.5.5 Fruchterman and Reingold layout",
    "text": "8.5.5 Fruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#modifying-network-nodes",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#modifying-network-nodes",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.5.6 Modifying network nodes",
    "text": "8.5.6 Modifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#modifying-edges",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#modifying-edges",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.5.7 Modifying edges",
    "text": "8.5.7 Modifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_edges",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_edges",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.6.1 Working with facet_edges()",
    "text": "8.6.1 Working with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_edges-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_edges-1",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.6.2 Working with facet_edges()",
    "text": "8.6.2 Working with facet_edges()\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#a-framed-facet-graph",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#a-framed-facet-graph",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.6.3 A framed facet graph",
    "text": "8.6.3 A framed facet graph\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_nodes",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-facet_nodes",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.6.4 Working with facet_nodes()",
    "text": "8.6.4 Working with facet_nodes()\nIn the code chunk below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-centrality-indices",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-centrality-indices",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.7.1 Computing centrality indices",
    "text": "8.7.1 Computing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-network-metrics",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-network-metrics",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.7.2 Visualising network metrics",
    "text": "8.7.2 Visualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-community",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-community",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.7.3 Visualising Community",
    "text": "8.7.3 Visualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.8.1 Data preparation",
    "text": "8.8.1 Data preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-the-first-interactive-network-graph",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-the-first-interactive-network-graph",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.8.2 Plotting the first interactive network graph",
    "text": "8.8.2 Plotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-layout",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-layout",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.8.3 Working with layout",
    "text": "8.8.3 Working with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-visual-attributes---nodes",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-visual-attributes---nodes",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.8.4 Working with visual attributes - Nodes",
    "text": "8.8.4 Working with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-visual-attributes---edges",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#working-with-visual-attributes---edges",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.8.5 Working with visual attributes - Edges",
    "text": "8.8.5 Working with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n\nThe argument arrows is used to define where to place the arrow.\nThe smooth argument is used to plot the edges using a smooth curve.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#interactivity",
    "title": "Hands-on Exercise 9: Visualising and Analysing Text Data",
    "section": "8.8.6 Interactivity",
    "text": "8.8.6 Interactivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.3.1 The Data",
    "text": "6.3.1 The Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-data",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.3.2 Importing the data",
    "text": "6.3.2 Importing the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#examining-the-data-structure",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#examining-the-data-structure",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.3.3 Examining the data structure",
    "text": "6.3.3 Examining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.3.4 Data Preparation",
    "text": "6.3.4 Data Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n}\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-the-calendar-heatmaps",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-the-calendar-heatmaps",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.3.5 Building the Calendar Heatmaps",
    "text": "6.3.5 Building the Calendar Heatmaps\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\n\n\n\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-multiple-calendar-heatmaps",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-multiple-calendar-heatmaps",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.3.6 Building Multiple Calendar Heatmaps",
    "text": "6.3.6 Building Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-multiple-calendar-heatmaps",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-multiple-calendar-heatmaps",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.3.7 Plotting Multiple Calendar Heatmaps",
    "text": "6.3.7 Plotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-multiple-calendar-heatmaps-1",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-multiple-calendar-heatmaps-1",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.3.8 Plotting Multiple Calendar Heatmaps",
    "text": "6.3.8 Plotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-1-data-import",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-1-data-import",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.4.1 Step 1: Data Import",
    "text": "6.4.1 Step 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-2-deriving-month-and-year-fields",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-2-deriving-month-and-year-fields",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.4.2 Step 2: Deriving month and year fields",
    "text": "6.4.2 Step 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-4-extracting-the-target-country",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-4-extracting-the-target-country",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.4.3 Step 4: Extracting the target country",
    "text": "6.4.3 Step 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-5-computing-year-average-arrivals-by-month",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-5-computing-year-average-arrivals-by-month",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.4.4 Step 5: Computing year average arrivals by month",
    "text": "6.4.4 Step 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#srep-6-plotting-the-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#srep-6-plotting-the-cycle-plot",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.4.5 Srep 6: Plotting the cycle plot",
    "text": "6.4.5 Srep 6: Plotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-1-data-import-1",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-1-data-import-1",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.5.1 Step 1: Data Import",
    "text": "6.5.1 Step 1: Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-2-plotting-the-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#step-2-plotting-the-slopegraph",
    "title": "Hands-on Exercise 6: Visual Multivariate Analysis",
    "section": "6.5.2 Step 2: Plotting the slopegraph",
    "text": "6.5.2 Step 2: Plotting the slopegraph\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\"\n                )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "As indicated by the office report and the accompanying infographic:\n\nThe average daily temperatures are expected to rise by 1.4 to 4.6 degrees, and\nThe difference in precipitation between the wet season (November to January) and the dry season (February and June to September) is anticipated to become more distinct.\n\n\n\n\n\nFor this take-home assignment, we are tasked to:\n\nSelect a weather station and retrieve historical daily data on temperature or rainfall from the website of the Meteorological Service Singapore.\nChoose records of daily temperature or rainfall for a month from the years 1983, 1993, 2003, 2013, and 2023, and then craft a data visualisation driven by analytics.\nIncorporate suitable interactive features to improve the experience of users in exploring data and/or in visual storytelling.\n\nFor this take home exercise 3, we have chosen the Changi weather station and decided to focus on the daily temperature data for the month of February across the years 1983, 1993, 2003, 2013, and 2023 to examine the hypothesis suggesting an increase in daily average temperatures between 1.4 to 4.6 degrees Celsius."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#setting-the-scene-for-this-take-home-exercise",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#setting-the-scene-for-this-take-home-exercise",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "As indicated by the office report and the accompanying infographic:\n\nThe average daily temperatures are expected to rise by 1.4 to 4.6 degrees, and\nThe difference in precipitation between the wet season (November to January) and the dry season (February and June to September) is anticipated to become more distinct."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "For this take-home assignment, we are tasked to:\n\nSelect a weather station and retrieve historical daily data on temperature or rainfall from the website of the Meteorological Service Singapore.\nChoose records of daily temperature or rainfall for a month from the years 1983, 1993, 2003, 2013, and 2023, and then craft a data visualisation driven by analytics.\nIncorporate suitable interactive features to improve the experience of users in exploring data and/or in visual storytelling.\n\nFor this take home exercise 3, we have chosen the Changi weather station and decided to focus on the daily temperature data for the month of February across the years 1983, 1993, 2003, 2013, and 2023 to examine the hypothesis suggesting an increase in daily average temperatures between 1.4 to 4.6 degrees Celsius."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-necessary-r-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-necessary-r-packages",
    "title": "Take-home Exercise 3",
    "section": "2.1 Loading Necessary R packages",
    "text": "2.1 Loading Necessary R packages\nWe will utilise the following packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\nggthemes is an R package that offers additional themes, geoms, and scales for ‘ggplot2’\n\nThe code which loads the R packages:\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse, dplyr, ggthemes)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#import-dataset",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#import-dataset",
    "title": "Take-home Exercise 3",
    "section": "2.2 Import dataset",
    "text": "2.2 Import dataset\nOf course our next step involves importing the dataset. As mentioned earlier, we will be analysing data from the Changi weather stations for the year 1983, 1993, 2003, 2013 and 2023.\nFirstly, we need to import the 5 csv files using read_csv. We want to read and combine all the files as feb_combined since they all the files have the common column names and same number of columns.\nAlso, we have found out that the 2023 dataset, latin characters are present on some of the columns.\n\nï..Station\n“Mean.Temperature..Â.C.”\n“Maximum.Temperature..Â.C.”\n“Minimum.Temperature..Â.C.”\n\nSince we are only focusing on temperature data, we will discard the columns related to rainfall and windspeed. Also, I will rename these columns below accordingly.\n\nMean Temperature (°C) -&gt; meantemp\nMaximum Temperature (°C) -&gt; maxtemp\nMinimum Temperature (°C) -&gt; mintemp\n\nThen I also will create a new column to find out the difference between the maxtemp and mintemp on a daily basis.\nThe following code snippet will outline the sequential steps we will undertake:\n\nlibrary(dplyr)\n\n# Function to read and preprocess each file\nread_and_preprocess &lt;- function(file_path, encoding = \"latin1\", is_2023 = FALSE) {\n  data &lt;- read.csv(file_path, fileEncoding = encoding)\n  \n  # If the file is for the year 2023, rename columns with encoding issues\n  if(is_2023) {\n    data &lt;- rename(data, \n                   Station = `ï..Station`, \n                   `Mean.Temperature...C.` = `Mean.Temperature..Â.C.`,\n                   `Maximum.Temperature...C.` = `Maximum.Temperature..Â.C.`,\n                   `Minimum.Temperature...C.` = `Minimum.Temperature..Â.C.`)\n  }\n  \n  # Select and rename columns for consistency\n  data %&gt;%\n    select(Station, Year, Month, Day, `Mean.Temperature...C.`, `Maximum.Temperature...C.`, `Minimum.Temperature...C.`) %&gt;%\n    rename(meantemp = `Mean.Temperature...C.`, \n           maxtemp = `Maximum.Temperature...C.`, \n           mintemp = `Minimum.Temperature...C.`) %&gt;%\n    mutate(difftemp = maxtemp - mintemp)\n}\n\n# Read and preprocess each file, with special handling for the 2023 file\nfeb_combined &lt;- bind_rows(\n  read_and_preprocess(\"data/CHANGI_FEB1983.csv\"),\n  read_and_preprocess(\"data/CHANGI_FEB1993.csv\"),\n  read_and_preprocess(\"data/CHANGI_FEB2003.csv\"),\n  read_and_preprocess(\"data/CHANGI_FEB2013.csv\"),\n  read_and_preprocess(\"data/CHANGI_FEB2023.csv\", is_2023 = TRUE)\n)\n\nAfterwards, we want to find out the average temperature across the years. We will name this column yearly_avg_temp.\n\n# Add a new column with the mean temperature for each year\nfeb_combined &lt;- feb_combined %&gt;%\n  group_by(Year) %&gt;%\n  mutate(yearly_avg_temp = mean(meantemp, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nNote\n\n\n\nThe code below is to display the combined file:\n\nDT::datatable(feb_combined, class= \"compact\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#scatterplot",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#scatterplot",
    "title": "Take-home Exercise 3",
    "section": "3.1 Scatterplot",
    "text": "3.1 Scatterplot\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(feb_combined, aes(x = as.Date(paste(Year, Month, Day, sep=\"-\")), y = meantemp)) +\n  geom_point(aes(text = paste(\"Date:\", paste(Year, Month, Day, sep=\"-\"), \"\\nTemp:\", meantemp, \"°C\")), size = 2, color = \"blue\") + # Keep points for daily temperatures\n  geom_line(data = feb_combined, aes(x = as.Date(paste(Year, Month, Day, sep=\"-\")), y = yearly_avg_temp, group = 1), color = \"red\", size = 0.5) + # Keep the red line for yearly average temperatures\n  scale_x_date(breaks = as.Date(c(\"1983-02-01\", \"1993-02-01\", \"2003-02-01\", \"2013-02-01\", \"2023-02-01\")),\n               labels = c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\"),\n               date_labels = \"%Y\") +\n  labs(title = \"Daily and Yearly Mean Temperature Over Years\",\n       x = \"Year\",\n       y = \"Temperature (°C)\") +\n  theme_minimal()\n\n# Convert to interactive plotly plot\ninteractive_p1 &lt;- ggplotly(p1, tooltip = \"text\")\n\n# Display the plot\ninteractive_p1\n\n\n\n\nThis scatter plot visualises two types of temperature data over a span of several years, from before 1983 to 2023:\n\nDaily Mean Temperature (Blue Dots): Each blue dot represents the mean temperature recorded on a specific day. The vertical axis shows the temperature in degrees Celsius (°C), while the horizontal axis represents the years. The exact date and temperature are displayed when you hover over a blue dot, as shown in the tooltip for the date 2003-2-23 with a mean temperature of 27.5 °C.\nAverage Annual Temperature (Red Line): The red line indicates the trend of the average annual temperature over the years. It appears to have a fluctuating pattern, with some years being warmer on average than others.\n\nThe scatter plot also suggests a wide range of daily temperatures within any given year, as seen by the vertical spread of blue dots for each year. The red line helps to identify whether there is an overall trend of increasing or decreasing average temperatures, which could be an indicator of climate patterns or changes. The plot is a useful way to visually compare daily temperatures to the average trend over a long time period.\n\n\n\n\n\n\nWhy is interactivity beneficial here?\n\n\n\n\nDetailed Information on Demand: The ability to hover over individual data points to obtain specific information (such as the exact date and temperature) allows us users to explore the data in depth without overwhelming the visual presentation. In the provided scatter plot above, this means we can see the exact temperature on a given day, which is crucial for detailed analysis or for identifying outliers and anomalies.\nClarity in a Dense Plot: With many data points, a static scatter plot can become cluttered and difficult to read. Interactivity allows us users to focus on individual points of interest without being distracted by the sheer volume of data.\nTrend Identification: By interacting with the data points along the trend line, we can observe how the annual average temperature changes over time, making it easier to spot patterns such as warming or cooling trends."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#lineplot",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#lineplot",
    "title": "Take-home Exercise 3",
    "section": "3.2 Lineplot",
    "text": "3.2 Lineplot\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n# Create the interactive line plot with customised hover text and x-axis ticks\np &lt;- plot_ly(data = feb_combined, x = ~Year, y = ~yearly_avg_temp, type = 'scatter', mode = 'lines+markers',\n             marker = list(size = 10, color = 'red'), line = list(color = 'red'),\n             hovertemplate = paste(\"Year: %{x}&lt;br&gt;Temperature: %{y} °C&lt;extra&gt;&lt;/extra&gt;\")) %&gt;%\n  layout(title = \"Yearly Average Temperatures (1983, 1993, 2003, 2013, 2023)\",\n         xaxis = list(title = \"Year\", \n                      tickvals = c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\"), # Specify which ticks to show\n                      ticktext = c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\")), # Specify labels for the ticks\n         yaxis = list(title = \"Yearly Average Temperature (°C)\"),\n         hovermode = \"closest\")\n\n# Render the plot with specified x-axis ticks\np\n\n\n\n\n\n\n\n\n\n\nKey Findings:\n\n\n\n\nInitial Point (1983): The graph starts at a peak with the average annual temperature recorded at 28.06 °C in 1983. This represents the highest recorded temperature over the 40-year span depicted.\nFirst Decade Drop (1993): There is a sharp decline over the next decade to 26.71 °C in 1993. This decrease of approximately 1.35 °C is quite significant, suggesting a notable cooling period during these ten years.\nRecovery Phase (2003): The year 2003 shows a rebound with the temperature rising to 27.09 °C. Although this is an increase of about 0.38 °C from 1993, it’s still below the starting temperature in 1983 by nearly 1 °C.\nLowest Point (2013): The year 2013 marks the lowest temperature on the plot at 26.53 °C. This further decrease suggests a continuation of the cooling trend, with temperatures dropping by approximately 0.56 °C from 2003 and 1.53 °C from 1983.\nPartial Recovery (2023): By 2023, the temperature rises again to 26.95 °C. This increase of 0.42 °C from 2013 indicates a slight warming trend. However, the temperature in 2023 is still below the initial 1983 temperature by 1.11 °C.\n\n\n\nThe overall trend appears to be a downward trajectory from 1983 to 2013 with a slight increase in 2023. However, the graph does not show a simple linear decrease; rather, it fluctuates, suggesting variability in average temperatures over time. This could be due to a variety of natural climatic cycles or other environmental factors influencing average temperatures."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#heatmap",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#heatmap",
    "title": "Take-home Exercise 3",
    "section": "3.3 Heatmap",
    "text": "3.3 Heatmap\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n# Ensure 'Year' is treated as a factor with only display the 5 years\nfeb_combined$Year &lt;- factor(feb_combined$Year, levels = c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\"))\n\n# Create the heat map with ggplot, specifying y-axis breaks\np &lt;- ggplot(feb_combined, aes(x = Day, y = Year, fill = meantemp)) + \n  geom_tile(color = \"white\", size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + # Using Tufte theme for a clean look\n  scale_fill_gradient(name = \"°C\", low = \"lightyellow\", high = \"red\") + # Adjust colour gradient\n  scale_y_discrete(limits = c(\"1983\", \"1993\", \"2003\", \"2013\", \"2023\")) + # Specify y-axis to show only these years\n  labs(x = NULL, \n       y = NULL, \n       title = \"Daily Mean Temperature in Changi for February\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8))\n\n# Convert the ggplot object to an interactive plotly object\ninteractive_p &lt;- ggplotly(p)\n\n# Display the interactive plot\ninteractive_p\n\n\n\n\nThis heatmap visualises the daily mean temperatures for the month of February across five different years: 1983, 1993, 2003, 2013, and 2023.\n\nThe X-axis represents the days of February, ranging from 1 to 28.\nThe Y-axis lists the years in descending order, with 2023 at the top and 1983 at the bottom.\nEach cell in the heatmap corresponds to a specific day in February for a given year.\nThe colour of each cell indicates the mean temperature for that day, according to the colour scale on the right side of the heatmap. The scale ranges from light colours (cooler temperatures) to dark colours (warmer temperatures). Lighter shades of the colour represent cooler temperatures, closer to 25°C, while darker shades signify warmer temperatures, approaching 28°C.\n\nFor instance, if one were to hover over a particular cell:\n\nThe day would be indicated.\nThe year would be shown.\nThe mean temperature for that specific day and year would be displayed.\n\nWith reference to the image below, we can hover over the 27th February 2024 with a mean temperature of 26.7°C.\n\nThe heatmap shows variations in temperature across different days and years at a glance. Warmer days are immediately noticeable with darker colours, while cooler days are indicated by lighter colours. One can observe patterns such as particularly warm or cool periods during February for each year and compare the overall temperature profile across years. It seems there are fluctuations in temperature from year to year, with some years having wider spreads of temperatures throughout the month, while others show more uniformity.\n\n\n\n\n\n\nWhy is interactivity useful here?\n\n\n\nInteractivity functionality in a heatmap, such as the ability to hover over cells to display specific data points, is particularly useful for several reasons:\nPrecision: While the colour gradations indicate temperature differences, precise values cannot be determined solely by sight, especially when dealing with a colour spectrum. Hovering to get exact figures allows for accurate data interpretation.\nDetail: A heatmap can only show so much detail at once. Interactivity allows users to delve into the data, seeing the exact mean temperature for any day of interest without overcrowding the visual with numbers.\nComparison: It enables quick and easy comparisons between different days or years. Users can hover over various parts of the heatmap to compare specific data points without referring to a legend or scale repeatedly.\nUser Engagement: Interactivity increases user engagement. Users who can interact with the data are more likely to spend time understanding the trends and anomalies presented.\nAccessibility: For those with colour vision deficiencies, distinguishing between colours might be challenging. Interactive elements that display numerical data can make the information accessible to a wider audience."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#box-plot-across-5-years",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#box-plot-across-5-years",
    "title": "Take-home Exercise 3",
    "section": "3.4 Box Plot across 5 years",
    "text": "3.4 Box Plot across 5 years\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nfeb_combined$Year &lt;- as.factor(feb_combined$Year)\n\n# Create the Plotly Box Plot\np &lt;- plot_ly(feb_combined, y = ~`meantemp`, x = ~Year, type = 'box',\n             color = ~Year, \n             hoverinfo = 'y+x') %&gt;%\n  layout(title = \"Box Plot of Daily Mean Temperatures for February Over Decades\",\n         xaxis = list(title = \"Year\"),\n         yaxis = list(title = \"Mean Temperature (°C)\"))\n\n# Display the plot\np\n\n\n\n\nThe box plot illustrates the distribution of daily mean temperatures for the month of February over five distinct years: 1983, 1993, 2003, 2013, and 2023. For each year, the data is summarised as follows:\n\n\n\n\n\n\nKey Findings\n\n\n\n1983:\n\nThe maximum daily mean temperature reached 28.8°C.\nThe upper quartile (Q3) temperature was 28.55°C, indicating that 75% of the days had a mean temperature of 28.55°C or lower.\nThe median temperature was 28.1°C, which is the midpoint of the data.\nThe lower quartile (Q1) temperature was 27.75°C, suggesting that 25% of the days had a mean temperature below this value.\nThe minimum temperature recorded was 26.8°C.\n\n1993:\n\nThe temperatures peaked at 27.5°C.\nThe third quartile was observed at 27°C.\nThe median temperature for this year was slightly lower at 26.75°C.\nThe first quartile was marked at 26.45°C.\nThere was a notable outlier at 25.5°C, which was significantly lower than the expected range.\n\n2003:\n\nThe highest daily mean temperature noted was 28.2°C.\nThe temperature at the third quartile was 27.77°C.\nThe median temperature was 27.35°C.\nThe first quartile temperature came in at 26.45°C.\nThe lowest temperature recorded for the month was 25.3°C.\n\n2013:\n\nThe maximum temperature reached a similar level as in 2003, at 28.3°C.\nThe upper quartile temperature decreased to 27.2°C.\nThe median temperature was 26.64°C, indicating a slight decrease from 2003.\nThe lower quartile was at 26°C. - The minimum temperature dropped to 24.6°C, showing a significant decrease from previous years.\n\n2023:\n\nThe highest temperature observed was 28°C.\nThe third quartile temperature was at 27.5°C.\nThe median temperature was 27.05°C, suggesting a slight uptick from 2013. - The first quartile was at 26.7°C.\nThe minimum temperature saw a slight increase from the previous decade at 24.9°C, with a noticeable outlier just below the lower fence of 25.6°C.\n\n\n\nFrom 1983 to 2023, there’s a noticeable fluctuation in temperatures with both the median and the interquartile range varying from year to year. The median temperature appears to show slight variations, without a clear upward or downward trend. However, there is evidence of increasing variability in temperatures, as seen in the wider interquartile ranges in the later years, particularly in 2023."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html",
    "title": "In-class Exercise 2: Horizon Plot",
    "section": "",
    "text": "Load Packages\nCode chunk below loads the packages:\n\npacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\n\n\nImport dataset\nCode chunk below imports the dataset:\n\naverp &lt;- read_csv(\"data/AVERP.csv\") %&gt;%\n  mutate(`Date` = dmy(`Date`))\n\n\n\nPlotting Horizon Plot"
  }
]